<!DOCTYPE html><html><head>
      <title>第四章</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      
        <script type="text/javascript">
          window.MathJax = ({"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"options":{},"loader":{}});
        </script>
        <script type="text/javascript" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
.markdown-preview.markdown-preview {
  /* 样式化按钮 */
  /* 当鼠标悬停在按钮上时改变背景颜色 */
  /* 响应式设计：针对移动端 */
}
.markdown-preview.markdown-preview body {
  line-height: 175%;
}
.markdown-preview.markdown-preview #toggleProofs {
  font: 0.8em;
  font-style: italic;
  padding: 5px 5px;
  background-color: #4CAF50;
  color: white;
  border: none;
  border-radius: 5px;
  cursor: pointer;
  float: right;
}
.markdown-preview.markdown-preview #toggleProofs:hover {
  background-color: #45a049;
}
.markdown-preview.markdown-preview details {
  border: 2px solid #e1eaed;
  /* 蓝色边框 */
  border-radius: 10px;
  /* 圆角 */
  padding: 0px 8px 0px 8px;
  /* 内边距 */
  margin-bottom: 8px;
  /* 底部外边距 */
  transition: box-shadow 0.3s ease;
  /* 阴影过渡效果 */
  line-height: 200%;
  /* 设置行间距为当前字体大小的125% */
}
.markdown-preview.markdown-preview details:hover {
  border: 2px solid #90c1f4;
  /* 蓝色边框 */
  border-radius: 10px;
  /* 圆角 */
  padding: 0px 8px 0px 8px;
  /* 内边距 */
  margin-bottom: 8px;
  /* 底部外边距 */
  transition: box-shadow 0.3s ease;
  /* 阴影过渡效果 */
  line-height: 200%;
  /* 设置行间距为当前字体大小的125% */
}
.markdown-preview.markdown-preview summary {
  font-weight: bold;
  font-style: italic;
}
.markdown-preview.markdown-preview .callout {
  font-weight: bold;
  font-size: medium;
  font-style: italic;
  color: #005792;
  /* 深蓝色 */
  background-color: #E7F7FF;
  /* 浅蓝色背景 */
  padding: 5px 5px;
  margin-bottom: 10px;
  border-radius: 5px;
  /* 添加圆角 */
}
.markdown-preview.markdown-preview .fixed-toc {
  position: fixed;
  /* 使用固定定位 */
  left: 0;
  /* 贴合窗口左侧 */
  top: 0;
  /* 贴合窗口顶部 */
  max-width: 400px;
  /* 目录最大宽度 */
  overflow-y: auto;
  /* 如果内容超出高度，则显示滚动条 */
  height: 100%;
  /* 目录的高度 */
  padding: 10px;
  /* 内边距 */
  z-index: -100;
  /* 使目录在最底层 */
}
@media (max-width: 768px) {
  .markdown-preview.markdown-preview .fixed-toc {
    padding: 10px;
    /* 内边距 */
    position: inherit;
    /* 取消固定定位 */
    z-index: 100;
    /* 使目录在最顶层 */
  }
}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<div class="fixed-toc">
<details open="">
    <summary>Contents</summary>
<ul>
<li><a href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81%E4%B8%8E%E7%89%B9%E5%BE%81%E5%87%BD%E6%95%B0">第四章 数字特征与特征函数</a>
<ul>
<li><a href="#%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81">数字特征</a>
<ul>
<li><a href="#%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B">数学期望</a>
<ul>
<li><a href="#%E7%A6%BB%E6%95%A3%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F">离散型随机变量</a></li>
<li><a href="#%E8%BF%9E%E7%BB%AD%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F">连续型随机变量</a></li>
</ul>
</li>
<li><a href="#%E6%96%B9%E5%B7%AE">方差</a></li>
<li><a href="#%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0">相关系数</a></li>
<li><a href="#%E7%9F%A9">矩</a></li>
<li><a href="#%E5%88%86%E4%BD%8D%E6%95%B0">分位数</a></li>
</ul>
</li>
<li><a href="#%E6%9D%A1%E4%BB%B6%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B">条件数学期望</a></li>
<li><a href="#%E7%86%B5%E4%B8%8E%E4%BF%A1%E6%81%AF">熵与信息</a></li>
<li><a href="#%E6%AF%8D%E5%87%BD%E6%95%B0">母函数</a>
<ul>
<li><a href="#%E6%AF%8D%E5%87%BD%E6%95%B0%E7%9A%84%E6%A6%82%E5%BF%B5">母函数的概念</a></li>
<li><a href="#%E7%8B%AC%E7%AB%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%92%8C%E7%9A%84%E6%AF%8D%E5%87%BD%E6%95%B0">独立随机变量和的母函数</a></li>
<li><a href="#%E9%9A%8F%E6%9C%BA%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%AF%8D%E5%87%BD%E6%95%B0">随机个随机变量的母函数</a></li>
</ul>
</li>
<li><a href="#%E7%89%B9%E5%BE%81%E5%87%BD%E6%95%B0">特征函数</a>
<ul>
<li><a href="#%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0%E7%9A%84%E5%86%8D%E7%94%9F%E6%80%A7">分布函数的再生性</a></li>
<li><a href="#%E5%A4%9A%E5%85%83%E7%89%B9%E5%BE%81%E5%87%BD%E6%95%B0">多元特征函数</a></li>
</ul>
</li>
<li><a href="#%E5%A4%9A%E5%85%83%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83">多元正态分布</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a></li>
</ul>
</li>
</ul>
</details>
</div>
<button id="toggleProofs">Toggle Proofs</button>
<script>
  document.getElementById('toggleProofs').addEventListener('click', function() {
    this.style.backgroundColor = this.style.backgroundColor === 'gray' ? '' : 'gray';
    var details = document.querySelectorAll('details > summary');
    for (var i = 0; i < details.length; i++) {
      if (details[i].textContent.includes('Proof')) {
        details[i].parentElement.open = !details[i].parentElement.open;
      }
    }
  });
</script>
<h2 id="第四章-数字特征与特征函数">第四章 数字特征与特征函数 </h2>
<h3 id="数字特征">数字特征 </h3>
<h4 id="数学期望">数学期望 </h4>
<h5 id="离散型随机变量">离散型随机变量 </h5>
<p><span class="callout">4.1.1 Definition: 数学期望</span></p>
<p>设<span class="mathjax-exps">$\xi$</span>为一离散型随机变量，它取值<span class="mathjax-exps">$x_1, x_2, x_3, \cdots$</span>对应的概率为<span class="mathjax-exps">$p_1, p_2, p_3, \cdots$</span>如果级数</p>
<p></p><div class="mathjax-exps">$$\sum_{i=1}^{\infty} x_i p_i$$</div><p></p>
<p>绝对收敛，则把它称为<span class="mathjax-exps">$\xi$</span>的数学期望(mathematical expectation)，简称期望、期望值或均值(mean)，记作<span class="mathjax-exps">$E\xi$</span>。</p>
<p><span class="callout">Example: 伯努利分布</span></p>
<p>事件<span class="mathjax-exps">$A$</span>发生的概率为<span class="mathjax-exps">$p$</span>，若以<span class="mathjax-exps">$1_A$</span>记其示性函数，即<span class="mathjax-exps">$A$</span>发生时取值1，否则取值0，则<br>
</p><div class="mathjax-exps">$$E 1_A = 1 \times p + 0 \times (1 - p) = p = P(A)$$</div><p></p>
<p><span class="callout">Example: 二项分布的数学期望</span></p>
<p>二项分布<span class="mathjax-exps">$p_k = \binom{n}{k} p^k q^{n-k}, \quad k=0,1,2,\cdots, n$</span></p>
<p></p><div class="mathjax-exps">$$\sum_{k=0}^n k p_k = \sum_{k=1}^n k \binom{n}{k} p^k q^{n-k} = n p \sum_{k=1}^n \binom{n-1}{k-1} p^{k-1} q^{n-k} = n p (p+q)^{n-1} = n p$$</div><p></p>
<p><span class="callout">Example: 泊松分布的数学期望</span></p>
<p>泊松分布<span class="mathjax-exps">$p_k = \frac{\lambda}{k!} e^{-\lambda}, \quad k=0,1,2,\cdots$</span></p>
<p></p><div class="mathjax-exps">$$\sum_{k=0}^{\infty} k p_k = \sum_{k=1}^{\infty} k \cdot \frac{\lambda^k}{k!} e^{-\lambda} = \lambda e^{-\lambda} \sum_{k=1}^{\infty} \frac{\lambda^{k-1}}{(k-1)!} = \lambda e^{-\lambda} \cdot e^{\lambda} = \lambda$$</div><p></p>
<p>由此看出，泊松分布的参数<span class="mathjax-exps">$\lambda$</span>就是它的期望值。</p>
<p><span class="callout">Example: 几何分布的数学期望</span></p>
<p>几何分布<span class="mathjax-exps">$p_k = q^{k-1} p, \quad k=1,2,\cdots$</span></p>
<p></p><div class="mathjax-exps">$$\sum_{k=1}^{\infty} k p_k = \sum_{k=1}^{\infty} k q^{k-1} p = p(1 + 2q + 3q^2 + \cdots) = p(q + q^2 + q^3 + \cdots)' = p\left(\frac{q}{1-q}\right)' = p\frac{1}{(1-q)^2} = \frac{1}{p}$$</div><p></p>
<p><span class="callout">Example: 数学期望不存在</span></p>
<p>随机变量<span class="mathjax-exps">$\xi$</span>取值<span class="mathjax-exps">$x_k = (-1)^k \frac{2^k}{k}, \quad k=1,2,\cdots$</span>，概率为<span class="mathjax-exps">$p_k = \frac{1}{2^k}$</span>，则由于<span class="mathjax-exps">$p_k \geqslant 0, \sum_{k=1}^{\infty} p_k = 1$</span>，因此它是概率分布，而且</p>
<p></p><div class="mathjax-exps">$$\sum_{k=1}^{\infty} x_k p_k = \sum_{k=1}^{\infty} (-1)^k \frac{1}{k} = -\ln 2$$</div><p></p>
<p>但由于</p>
<p></p><div class="mathjax-exps">$$\sum_{k=1}^{\infty} |x_k| p_k = \sum_{k=1}^{\infty} \frac{1}{k} = \infty$$</div><p></p>
<p>因此按定义<span class="mathjax-exps">$\xi$</span>的数学期望不存在。</p>
<p>这个例子展示了如何计算几何分布的数学期望。</p>
<h5 id="连续型随机变量">连续型随机变量 </h5>
<p><span class="callout">4.1.2 Definition: 连续型随机变量的数学期望</span></p>
<blockquote>
<p>设<span class="mathjax-exps">$\xi$</span>为具有密度函数<span class="mathjax-exps">$p(x)$</span>的连续型随机变量，当积分<span class="mathjax-exps">$\int_{-\infty}^{\infty} x p(x) \, dx$</span>绝对收敛时，我们称它为<span class="mathjax-exps">$\xi$</span>的数学期望（或均值），记作<span class="mathjax-exps">$E\xi$</span>，即<br>
</p><div class="mathjax-exps">$$E\xi = \int_{-\infty}^{\infty} x p(x) \, dx$$</div><p></p>
</blockquote>
<p><span class="callout">Example: 正态分布的数学期望</span></p>
<blockquote>
<p>正态分布<span class="mathjax-exps">$N(\mu, \sigma^2)$</span>。</p>
</blockquote>
<p></p><div class="mathjax-exps">$$\int_{-\infty}^{\infty} x p(x) \, dx = \int_{-\infty}^{\infty} x \frac{1}{\sqrt{2\pi}\sigma} e^{-(x-\mu)^2/(2\sigma^2)} \, dx = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} (\sigma z + \mu) e^{-z^2/2} \, dz = \frac{\mu}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{-z^2/2} \, dz = \mu$$</div><p></p>
<p>可见<span class="mathjax-exps">$N(\mu, \sigma^2)$</span>中的参数<span class="mathjax-exps">$\mu$</span>正是它的数学期望。</p>
<p><span class="callout">Example: 指数分布的数学期望</span></p>
<blockquote>
<p>指数分布<span class="mathjax-exps">$p(x) = \lambda e^{-\lambda x}, \quad x \geqslant 0$</span>。</p>
</blockquote>
<p></p><div class="mathjax-exps">$$\int_0^{\infty} x \lambda e^{-\lambda x} \, dx = -\int_0^{\infty} x \, d e^{-\lambda x} = \int_0^{\infty} e^{-\lambda x} \, dx = \frac{1}{\lambda}$$</div><p></p>
<p><span class="callout">Example: 柯西分布的数学期望</span></p>
<blockquote>
<p>柯西分布<span class="mathjax-exps">$p(x) = \frac{1}{\pi} \cdot \frac{1}{1+x^2}$</span>。</p>
</blockquote>
<p>由于</p>
<p></p><div class="mathjax-exps">$$\int_{-\infty}^{\infty} |x| \cdot \frac{1}{\pi(1+x^2)} \, dx = \infty$$</div><p></p>
<p>因此柯西分布的数学期望不存在。</p>
<p>对于一般情况下，使用斯蒂尔斯积分：</p>
<p><span class="callout">4.1.3 Definition: 数学期望</span></p>
<blockquote>
<p>若 <span class="mathjax-exps">$\xi$</span> 的分布函数为 <span class="mathjax-exps">$F(x)$</span>，则定义<br>
</p><div class="mathjax-exps">$$E\xi = \int_{-\infty}^{\infty} x dF(x)$$</div><p></p>
<p>为 <span class="mathjax-exps">$\xi$</span> 的数学期望（或均值）。要求上述积分绝对收敛，否则数学期望不存在。</p>
</blockquote>
<p><span class="callout">4.1.4 Theorem: 随机变量函数函数的数学期望</span></p>
<blockquote>
<p>若<span class="mathjax-exps">$g(x)$</span>是一元博雷尔函数，而<span class="mathjax-exps">$\eta = g(\xi)$</span>，则<br>
</p><div class="mathjax-exps">$$\int_{-\infty}^{\infty} y dF_{\eta}(y) = \int_{-\infty}^{\infty} g(x) dF_{\xi}(x)$$</div><p></p>
<p>即这两个积分中，若有一个存在，则另一个也存在，而且两者相等。</p>
</blockquote>
<p>该定理使得我们计算随机变量函数的数学期望时不需要先求解函数的分布函数，而是直接利用原随机变量的分布函数即可。</p>
<p><span class="callout">4.1.4 Definition: 随机向量数学期望</span></p>
<blockquote>
<p>随机向量 <span class="mathjax-exps">$\left(\xi_1,\xi_2,\cdots,\xi_n\right)$</span> 的数学期望为 <span class="mathjax-exps">$\left(E\xi_1, E\xi_2,\cdots, E\xi_n\right)$</span>，其中<br>
</p><div class="mathjax-exps">$$E\xi_i=\int_{-\infty}^{\infty}\cdots\int_{-\infty}^{\infty} x_i d F\left(x_1,\cdots, x_n\right)=\int_{-\infty}^{\infty} x_i d F_i\left(x_i\right)$$</div><p></p>
<p>这里 <span class="mathjax-exps">$F_i\left(x_i\right)$</span> 是 <span class="mathjax-exps">$\xi_i$</span> 的分布函数 <span class="mathjax-exps">$\left(i=1,2,\cdots, n\right)$</span>。</p>
</blockquote>
<h4 id="方差">方差 </h4>
<p><span class="callout">4.2.1 Definition: 随机变量方差</span></p>
<blockquote>
<p>若 <span class="mathjax-exps">$E(\xi-E\xi)^2$</span> 存在，则称它为随机变量 <span class="mathjax-exps">$\xi$</span> 的方差(variance)，并记为 <span class="mathjax-exps">$D\xi$</span>，而 <span class="mathjax-exps">$\sqrt{D\xi}$</span> 称为根方差、均方差或更多地称为标准差(standard deviation)。</p>
</blockquote>
<p>利用数学期望的线性性质，可以得到方差的另一种表达形式：</p>
<p></p><div class="mathjax-exps">$$\begin{align*} D\xi &amp;= E(\xi-E\xi)^2 = E\left[\xi^2-2\xi\cdot E\xi+(E\xi)^2\right] \\ &amp;= E\xi^2-2 E\xi\cdot E\xi+(E\xi)^2 = E\xi^2-(E\xi)^2 \end{align*}$$</div><p></p>
<p><span class="callout">Example: 伯努利分布方差</span></p>
<p></p><div class="mathjax-exps">$$\begin{gather*} E\xi^2 = 1^2 \cdot p + 0^2 \cdot (1 - p) = p\\ D\xi = E\xi^2 - (E\xi)^2 = p - p^2 = pq \end{gather*}$$</div><p></p>
<p>当 <span class="mathjax-exps">$p = q = \frac{1}{2}$</span> 时方差最大——投币最难预测，预测阴晴则较易。</p>
<p><span class="callout">Example: 二项分布方差</span></p>
<p></p><div class="mathjax-exps">$$\begin{aligned} D \xi  &amp;= E \xi ^2 - (E \xi )^2 \\ &amp;= \sum_{k=0}^{n} k^2 C_n^k p^k (1 - p)^{n-k} - (np)^2 \\ &amp;= \sum_{k=0}^{n} k \cdot np C_{n-1}^{k-1} p^{k-1} (1 - p)^{n-k} - (np)^2 \\ &amp;= np(\sum_{k=1}^{n} (k - 1) C_{n-1}^{k-1} p^{k-1} (1 - p)^{n-k} + \sum_{k=1}^{n} C_{n-1}^{k-1} p^{k-1} (1 - p)^{n-k}) - (np)^2 \\ &amp;= np(\sum_{k=0}^{n-1} k C_{n-1}^{k} p^k (1 - p)^{n-1-k} + \sum_{k=1}^{n} C_{n-1}^{k-1} (1 - p)^{n-k} p^{k-1}) - (np)^2 \\ &amp;= np(E\xi + (p + (1 - p)^{n-1}) - (np)^2 \\ &amp;= np((n - 1)p + 1) - n^2 p^2 \\ &amp;= np(1 - p) \end{aligned}$$</div><p></p>
<p>该定理利用独立性可以显然得出结果。</p>
<p><span class="callout">Example: 泊松分布方差</span></p>
<p></p><div class="mathjax-exps">$$\begin{gather*} E\xi^2 = \sum_{k=0}^{\infty} k^2 p_k = \sum_{k=1}^{\infty} k \frac{\lambda^k e^{-\lambda}}{k!} = \sum_{k=1}^{\infty} k \frac{\lambda^k}{(k-1)!} e^{-\lambda} \\ $= \lambda \sum_{k=0}^{\infty} (k+1) \frac{\lambda^k}{k!} e^{-\lambda} = \lambda^2 + \lambda \\ $D\xi = E\xi^2 - (E\xi)^2 = \lambda^2 + \lambda - \lambda^2 = \lambda \end{gather*}$$</div><p></p>
<p>均值与方差都是 <span class="mathjax-exps">$\lambda$</span>。</p>
<p><span class="callout">Example: 均匀分布方差</span></p>
<p></p><div class="mathjax-exps">$$\begin{gather*} E\xi = \int_{a}^{b} x \frac{1}{b-a} dx = \frac{b+a}{2}\\ E\xi^2 = \int_{a}^{b} x^2 \frac{1}{b-a} dx = \frac{b^2 + ab + a^2}{3}\\ D\xi = E\xi^2 - (E\xi)^2 = \frac{b^2 + ab + a^2}{3} - \left(\frac{b+a}{2}\right)^2 = \frac{(b-a)^2}{12} \end{gather*}$$</div><p></p>
<p><span class="callout">Example:正态分布方差</span></p>
<p></p><div class="mathjax-exps">$$\begin{align*} D\xi &amp;= \int_{-\infty}^{\infty} (x-\mu)^2 \frac{1}{\sqrt{2\pi}\sigma} e^{-(x-\mu)^2/(2\sigma^2)} dx \\ &amp;= \frac{\sigma^2}{\sqrt{2\pi}} \int_{-\infty}^{\infty} z^2 e^{-z^2/2} dz \\ &amp;= \frac{\sigma^2}{\sqrt{2\pi}} \left[ \left( -ze^{-z^2/2} \right) \bigg|_{-\infty}^{\infty} + \int_{-\infty}^{\infty} e^{-z^2/2} dz \right] \\ &amp;= \frac{\sigma^2}{\sqrt{2\pi}} \sqrt{2\pi} = \sigma^2   \end{align*}$$</div><p></p>
<p>方差的性质</p>
<ol>
<li>
<p>常数的方差为 0。</p>
</li>
<li>
<p><span class="mathjax-exps">$D(\xi + c) = D\xi$</span>，这里 <span class="mathjax-exps">$c$</span> 是常数。</p>
</li>
<li>
<p><span class="mathjax-exps">$D(c\xi) = c^2 D\xi$</span>，这里 <span class="mathjax-exps">$c$</span> 是常数。<br>
对于随机变量 <span class="mathjax-exps">$\xi$</span>，若它的数学期望 <span class="mathjax-exps">$E\xi$</span> 及方差 <span class="mathjax-exps">$D\xi$</span> 都存在，而且 <span class="mathjax-exps">$D\xi &gt; 0$</span>，有时要考虑标准化了的随机变量<br>
</p><div class="mathjax-exps">$$\xi^* = \frac{\xi - E\xi}{\sqrt{D\xi}}$$</div><p></p>
<p>显然 <span class="mathjax-exps">$E\xi^* = 0, D\xi^* = 1$</span>。</p>
</li>
<li>
<p>若 <span class="mathjax-exps">$c \neq E\xi$</span>，则 <span class="mathjax-exps">$D\xi &lt; E(\xi - c)^2$</span>。<br>
<span id="Var-1"></span></p>
</li>
</ol>
<details open="">
    <summary>Proof:</summary>
<p></p><div class="mathjax-exps">$$D\xi = E(\xi - E\xi)^2 = E(\xi - c)^2 - (c - E\xi)^2$$</div><p></p>
</details>
<p>这个性质表明数学期望具有一个重要的极值性质：在 <span class="mathjax-exps">$E(\xi - c)^2$</span> 中，当 <span class="mathjax-exps">$c = E\xi$</span> 时达到极小；这也说明在 <span class="mathjax-exps">$D\xi$</span> 的定义中取 <span class="mathjax-exps">$c = E\xi$</span> 的合理性。</p>
<p><span class="callout">Theorem: 切比雪夫不等式</span><br>
<span id="Chebyshev-inequality"></span></p>
<blockquote>
<p>对于任何具有有限方差的随机变量 <span class="mathjax-exps">$\xi$</span>，都有<br>
</p><div class="mathjax-exps">$$P\{|\xi-E\xi|\geqslant\varepsilon\}\leqslant\frac{D\xi}{\varepsilon^2}$$</div><p></p>
</blockquote>
<p>其中 <span class="mathjax-exps">$\varepsilon$</span> 是任一正数。</p>
<details open="">
    <summary>Proof:</summary>
<p>若 <span class="mathjax-exps">$F(x)$</span> 是 <span class="mathjax-exps">$\xi$</span> 的分布函数，则显然有</p>
<p></p><div class="mathjax-exps">$$\begin{align*} D\xi=\int_{-\infty}^{\infty}(x-E\xi)^2 d F(x)&amp;\geqslant\int_{|x-E\xi|\geqslant\varepsilon}(x-E\xi)^2 d F(x) \\ &amp;\geqslant\int_{|x-E\xi|\geqslant\varepsilon}\varepsilon^2 d F(x) =\varepsilon^2 P\left\{|\xi-E\xi|\geqslant\varepsilon\right\} \end{align*}$$</div><p></p>
<p>有时把该不等式改写成<br>
</p><div class="mathjax-exps">$$P\{|\xi-E\xi|&lt;\varepsilon\}\geqslant 1-\frac{D\xi}{\varepsilon^2}$$</div><p></p>
<p>或</p>
<p></p><div class="mathjax-exps">$$P\left\{\left|\frac{\xi-E\xi}{\sqrt{D\xi}}\right|\geqslant\delta\right\}\leqslant\frac{1}{\delta^2}$$</div><p></p>
</details>
<p>切比雪夫不等式利用随机变量 <span class="mathjax-exps">$\xi$</span> 的数学期望 <span class="mathjax-exps">$E\xi$</span> 及方差 <span class="mathjax-exps">$D\xi=\sigma^2$</span> 对 <span class="mathjax-exps">$\xi$</span> 的概率分布进行估计。因为只利用数学期望及方差就描述了随机变量的重要情况，因此它在理论研究及实际应用中都很有价值。</p>
<p>下面给出典型分布的均值和方差<br>
<span id="mu-sigma-table"></span></p>
<table>
<thead>
<tr>
<th style="text-align:center">分布</th>
<th style="text-align:center">均值<span class="mathjax-exps">$\mu$</span></th>
<th style="text-align:center">方差<span class="mathjax-exps">$D$</span></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">伯努利</td>
<td style="text-align:center"><span class="mathjax-exps">$p$</span></td>
<td style="text-align:center"><span class="mathjax-exps">$pq$</span></td>
</tr>
<tr>
<td style="text-align:center">二项分布</td>
<td style="text-align:center"><span class="mathjax-exps">$np$</span></td>
<td style="text-align:center"><span class="mathjax-exps">$npq$</span></td>
</tr>
<tr>
<td style="text-align:center">泊松分布</td>
<td style="text-align:center"><span class="mathjax-exps">$\lambda$</span></td>
<td style="text-align:center"><span class="mathjax-exps">$\lambda$</span></td>
</tr>
<tr>
<td style="text-align:center">几何分布</td>
<td style="text-align:center"><span class="mathjax-exps">$\frac{1}{p}$</span></td>
<td style="text-align:center"><span class="mathjax-exps">$\frac{1-p}{p^2}$</span></td>
</tr>
<tr>
<td style="text-align:center">正态分布</td>
<td style="text-align:center"><span class="mathjax-exps">$\mu$</span></td>
<td style="text-align:center"><span class="mathjax-exps">$\sigma^2$</span></td>
</tr>
<tr>
<td style="text-align:center">指数分布</td>
<td style="text-align:center"><span class="mathjax-exps">$\frac{1}{\lambda}$</span></td>
<td style="text-align:center"><span class="mathjax-exps">$\frac{1}{\lambda^2}$</span></td>
</tr>
<tr>
<td style="text-align:center">均匀分布</td>
<td style="text-align:center"><span class="mathjax-exps">$\frac{a+b}{2}$</span></td>
<td style="text-align:center"><span class="mathjax-exps">$\frac{(b-a)^2}{12}$</span></td>
</tr>
<tr>
<td style="text-align:center">超几何分布</td>
<td style="text-align:center"><span class="mathjax-exps">$\frac{nM}{N}$</span></td>
<td style="text-align:center"><span class="mathjax-exps">$\frac{nM}{N}\left(1 - \frac{M}{N}\right)\frac{N-n}{N-1}$</span></td>
</tr>
<tr>
<td style="text-align:center">伽马分布</td>
<td style="text-align:center"><span class="mathjax-exps">$\frac{\alpha}{\lambda}$</span></td>
<td style="text-align:center"><span class="mathjax-exps">$\frac{\alpha}{\lambda^2}$</span></td>
</tr>
</tbody>
</table>
<h4 id="相关系数">相关系数 </h4>
<p>对于随机向量，只用方差是不够的，还需要考虑随机变量之间的关系。<br>
计算 <span class="mathjax-exps">$\xi \pm \eta$</span> 的方差：<br>
</p><div class="mathjax-exps">$$\begin{align*}   D(\xi \pm \eta) &amp;= E[(\xi \pm \eta) - (E\xi \pm E\eta)]^2 \\ &amp;= E(\xi - E\xi)^2 + E(\eta - E\eta)^2 \pm 2 E[(\xi - E\xi)(\eta - E\eta)] \\ &amp;= D\xi + D\eta \pm 2 E[(\xi - E\xi)(\eta - E\eta)] \end{align*}$$</div><p></p>
<p>这启发我们引入 <span class="mathjax-exps">$E[(\xi - E\xi)(\eta - E\eta)]$</span> 。</p>
<p><span class="callout">Definition 4.2.2: 协方差</span></p>
<blockquote>
<p>称 <span class="mathjax-exps">$\sigma_{ij} = \operatorname{cov}(\xi_i, \xi_j) = E[(\xi_i - E\xi_i)(\xi_j - E\xi_j)] \quad i, j = 1, 2, \ldots, n$</span> 为 <span class="mathjax-exps">$\xi_i$</span> 与 <span class="mathjax-exps">$\xi_j$</span> 的协方差(covariance)。</p>
</blockquote>
<p>不难验算<br>
</p><div class="mathjax-exps">$$\begin{gather*} \operatorname{}{cov}(\xi_i, \xi_j) = E\xi_i \xi_j - E\xi_i \cdot E\xi_j \\ D\left(\sum_{i=1}^{n} \xi_i\right) = \sum_{i=1}^{n} D\xi_i + 2 \sum_{1 \leq i &lt; j \leq n} \text{cov}(\xi_i, \xi_j) \end{gather*}$$</div><p></p>
<p>特别地<br>
</p><div class="mathjax-exps">$$D(\xi_i \pm \xi_j) = D\xi_i + D\xi_j \pm 2\text{cov}(\xi_i, \xi_j)$$</div><p></p>
<p>方差是协方差的特例，显然 <span class="mathjax-exps">$\sigma_{ii} = D\xi_i$</span>。矩阵<br>
</p><div class="mathjax-exps">$$\Sigma = \begin{pmatrix} \sigma_{11} &amp; \sigma_{12} &amp; \cdots &amp; \sigma_{1n} \\ \sigma_{21} &amp; \sigma_{22} &amp; \cdots &amp; \sigma_{2n} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \sigma_{n1} &amp; \sigma_{n2} &amp; \cdots &amp; \sigma_{nn} \end{pmatrix}$$</div><p></p>
<p>称为 <span class="mathjax-exps">$\xi$</span> 的协方差矩阵，简记作 <span class="mathjax-exps">$D\xi$</span>，显然这是一个对称矩阵。</p>
<p>此外，对任何随机向量和期望向量，有<br>
</p><div class="mathjax-exps">$$\begin{align*} X=&amp;\left[\begin{array}{cccc} X_1&amp; X_2&amp;\cdots&amp; X_n\end{array}\right]^T\\ \mu=&amp;\left[\begin{array}{cccc}\mu_1&amp;\mu_2&amp;\cdots&amp;\mu_n\end{array}\right]^T \end{align*}$$</div><p></p>
<p>所以：<span class="mathjax-exps">\(\Sigma=E\left[(X-\mu)(X-\mu)^T\right]\)</span><br>
对任意实向量y:</p>
<p></p><div class="mathjax-exps">$$\begin{align*} &amp; y^T\Sigma y= y^T E[(X-\mu)(X-\mu)^T] y\\ &amp;= E[ y^T(X-\mu)(X-\mu)^T y]\\ &amp;= E[\left((X-\mu)^T y\right)^T\left((X-\mu)^T y\right)]\\ &amp;= E[\left\|(X-\mu)^T y\right\|^2]\geq 0 \end{align*}$$</div><p></p>
<p>因此 <span class="mathjax-exps">$\Sigma$</span> 是一个非负定矩阵，所以有 <span class="mathjax-exps">$\det \Sigma \geq 0$</span></p>
<p>更常用的是如下“标准化”了的协方差。</p>
<p><span class="callout">4.2.3 Definition: 相关系数</span></p>
<blockquote>
<p>称 <span class="mathjax-exps">$\rho_{ij} = \frac{\text{cov}(\xi_i, \xi_j)}{\sqrt{D\xi_i D\xi_j}}$</span> 为 <span class="mathjax-exps">$\xi_i$</span> 与 <span class="mathjax-exps">$\xi_j$</span> 的相关系数(correlation coefficient)，这里要求 <span class="mathjax-exps">$D\xi_i$</span> 与 <span class="mathjax-exps">$D\xi_j$</span> 不为零。</p>
</blockquote>
<p>相关系数的优点是排除了量纲的影响，且有 <span class="mathjax-exps">$-1 \leq \rho_{ij} \leq 1$</span>。<br>
由于<br>
</p><div class="mathjax-exps">$$\rho_{a\xi+b, c\eta+d}= \frac{\text{cov}(a \xi+b, c \eta + d)}{ \sqrt{D(a\xi+b) D(c\eta+d)} }  =  \frac{ac \text{cov}(\xi,\eta)}{|a c|\sqrt{D\xi}\sqrt{D\eta}}=\rho_{\xi\eta}$$</div><p></p>
<p>相关系数在线性变化下保持不变，即 <span class="mathjax-exps">$a \xi + b$</span> 与 <span class="mathjax-exps">$c \eta + d$</span> 的相关系数仍为 <span class="mathjax-exps">$\rho _{\xi \eta }$</span>。</p>
<p>由于 <span class="mathjax-exps">$E\frac{\xi_i - E\xi_i}{\sqrt{D\xi_i}} = 0, D\frac{\xi_i - E\xi_i}{\sqrt{D\xi_i}} = 1$</span>，所以相关系数就是标准化随机变量的协方差。</p>
<p><span class="callout">4.2.1 Theorem: Cauchy-Schwarz 不等式</span></p>
<blockquote>
<p>对任意随机变量<span class="mathjax-exps">$\xi$</span>与<span class="mathjax-exps">$\eta$</span>都有<br>
</p><div class="mathjax-exps">$$|E\xi\eta|^2 \leq E\xi^2 \cdot E\eta^2$$</div><p></p>
<p>等式成立当且仅当<br>
</p><div class="mathjax-exps">$$P\left\{\eta=t_0\xi\right\}=1$$</div><p></p>
<p><span class="mathjax-exps">$t_0$</span>为常数。</p>
</blockquote>
<p>由该定理可以得到相关系数的性质：<br>
<span class="mathjax-exps">$|\rho|\leqslant 1$</span>，并且 <span class="mathjax-exps">\(\rho=1\)</span> 当且仅当<br>
</p><div class="mathjax-exps">$$P\left\{\frac{\xi-E\xi}{\sqrt{D\xi}}=\frac{\eta-E\eta}{\sqrt{D\eta}}\right\}=1$$</div><p></p>
<p>而 <span class="mathjax-exps">\(\rho=-1\)</span> 当且仅当<br>
</p><div class="mathjax-exps">$$P\left\{\frac{\xi-E\xi}{\sqrt{D\xi}}=-\frac{\eta-E\eta}{\sqrt{D\eta}}\right\}=1$$</div><p></p>
<p>当 <span class="mathjax-exps">\(\rho=\pm 1\)</span> 时，<span class="mathjax-exps">\(\xi\)</span> 与 <span class="mathjax-exps">\(\eta\)</span> 存在着完全线性关系，这时如果给定一个随机变量之值，另一个随机变量的值便完全决定。<span class="mathjax-exps">\(\rho=1\)</span> 时，称为完全正相关；<span class="mathjax-exps">\(\rho=-1\)</span> 时，称为完全负相关。</p>
<p><span class="callout">4.2.4 Definition: 随机变量的不相关性</span></p>
<blockquote>
<p>若随机变量<span class="mathjax-exps">$\xi$</span>与<span class="mathjax-exps">$\eta$</span>的相关系数<span class="mathjax-exps">$\rho=0$</span>，则我们称<span class="mathjax-exps">$\xi$</span>与<span class="mathjax-exps">$\eta$</span>不相关。</p>
</blockquote>
<p><span class="callout">不相关随机变量的性质</span></p>
<blockquote>
<p>对随机变量<span class="mathjax-exps">$\xi$</span>与<span class="mathjax-exps">$\eta$</span>，下面事实是等价的：<br>
(1) <span class="mathjax-exps">$\operatorname{cov}(\xi,\eta)=0;$</span><br>
(2) <span class="mathjax-exps">$\xi$</span>与<span class="mathjax-exps">$\eta$</span>不相关;<br>
(3) <span class="mathjax-exps">$E\xi\eta=E\xi E\eta;$</span><br>
(4) <span class="mathjax-exps">$D(\xi+\eta)=D\xi+D\eta.$</span></p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>显然(1)与(2)是等价的。由于<br>
</p><div class="mathjax-exps">$$\operatorname{cov}(\xi,\eta)=E\xi\eta-E\xi\cdot E\eta$$</div><p></p>
<p>因此(1)与(3)等价。又由于</p>
<p></p><div class="mathjax-exps">$$D(\xi+\eta)=D\xi+D\eta+2\operatorname{cov}(\xi,\eta)$$</div><p></p>
<p>因此(1)与(4)等价。</p>
</details>
<p><span class="callout">Theorem: 独立性与相关性</span></p>
<blockquote>
<p>若 <span class="mathjax-exps">$\xi$</span> 与 <span class="mathjax-exps">$\eta$</span> 独立，则 <span class="mathjax-exps">$\xi$</span> 与 <span class="mathjax-exps">$\eta$</span> 不相关.</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>因为 <span class="mathjax-exps">$\xi$</span> 与 <span class="mathjax-exps">$\eta$</span> 独立，故其密度函数 <span class="mathjax-exps">$p(x,y) = p_1(x)p_2(y)$</span>，因此<br>
</p><div class="mathjax-exps">$$\begin{align*} \text{cov}(\xi, \eta) &amp;= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} (x - E\xi)(y - E\eta)p(x,y) \, dx \, dy \\ &amp;= \int_{-\infty}^{\infty} (x - E\xi)p_1(x) \, dx \cdot \int_{-\infty}^{\infty} (y - E\eta)p_2(y) \, dy = 0 \end{align*}$$</div><p></p>
</details>
<p>结合性质 2 及性质 3 可得：若 <span class="mathjax-exps">$\xi$</span> 与 <span class="mathjax-exps">$\eta$</span> 独立，则 <span class="mathjax-exps">$E\xi\eta = E\xi \cdot E\eta$</span> 及 <span class="mathjax-exps">$D(\xi + \eta) = D\xi + D\eta$</span> 成立。同样的论证可以证明类似的结论在 <span class="mathjax-exps">$n$</span> 个随机变量的场合也成立，即若 <span class="mathjax-exps">$\xi_1, \xi_2, \cdots, \xi_n$</span> 是相互独立的随机变量，则</p>
<p></p><div class="mathjax-exps">$$\begin{gathered} E\xi_1\xi_2\cdots\xi_n = E\xi_1 E\xi_2 \cdots E\xi_n\\ D(\xi_1 + \xi_2 + \cdots + \xi_n) = D\xi_1 + D\xi_2 + \cdots + D\xi_n  \end{gathered}$$</div><p></p>
<p>由独立性可以推出不相关性，但是反过来是不成立的。实际上，相关性只表示了线性关系，而独立性则表示了更强的关系。<br>
一般地，若 <span class="mathjax-exps">$\xi$</span> 服从对称分布，则 <span class="mathjax-exps">$\eta = \xi^2$</span> 或 <span class="mathjax-exps">$\eta = |\xi|$</span> 与 <span class="mathjax-exps">$\xi$</span> 不相关但不独立。但对于二元正态分布，不相关性与独立性是等价的。</p>
<p><span class="callout">Theorem: 二值随机变量的不相关性与独立性</span></p>
<blockquote>
<p>若<span class="mathjax-exps">$\xi$</span>与<span class="mathjax-exps">$\eta$</span>都是二值随机变量，则不相关性与独立性是等价的。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>设<span class="mathjax-exps">$\xi$</span>取二值<span class="mathjax-exps">$a$</span>及<span class="mathjax-exps">$c$</span>，<span class="mathjax-exps">$\eta$</span>取二值<span class="mathjax-exps">$b$</span>及<span class="mathjax-exps">$d$</span>，下面证明由<span class="mathjax-exps">$\rho_{\xi\eta}=0$</span>可推得<span class="mathjax-exps">$\xi$</span>与<span class="mathjax-exps">$\eta$</span>独立。<br>
记<span class="mathjax-exps">$A=\{\xi=a\}, B=\{\eta=b\}$</span><br>
从而<span class="mathjax-exps">$\bar{A}=\{\xi=c\},\quad\bar{B}=\{\eta=d\}$</span><br>
于是它们的示性函数<br>
</p><div class="mathjax-exps">$$1_A=\frac{\xi-c}{a-c},\quad 1_B=\frac{\eta-d}{b-d}$$</div><p></p>
<p>由<span class="mathjax-exps">$\operatorname{cov}(1_A, 1_B)=E 1_A 1_B-E 1_A\cdot E 1_B=P(A B)-P(A) P(B)$</span><br>
</p><div class="mathjax-exps">$$D 1_A=P(A) P(\bar{A}),\quad D 1_B=P(B) P(\bar{B})$$</div><p></p>
<p>得到<br>
</p><div class="mathjax-exps">$$\rho_{1 A 1 B}=\frac{P(A B)-P(A) P(B)}{\sqrt{P(A) P(\bar{A}) P(B) P(\bar{B})}}=0$$</div><p></p>
<p>这是因为<span class="mathjax-exps">$1_A$</span>与<span class="mathjax-exps">$1_B$</span>分别为<span class="mathjax-exps">$\xi$</span>与<span class="mathjax-exps">$\eta$</span>的线性变换，而后者不相关。</p>
<p>因而<span class="mathjax-exps">$P(A B)=P(A) P(B)$</span>，即</p>
<p></p><div class="mathjax-exps">$$P\{\xi=a,\eta=b\} = P\{\xi=a \} P\{\eta=b\}$$</div><p></p>
<p>再由<span class="mathjax-exps">$(A,\bar{B}),(\bar{A}, B)$</span>及<span class="mathjax-exps">$(\bar{A},\bar{B})$</span>的独立性可知</p>
<p></p><div class="mathjax-exps">$$\begin{align*} P\{\xi=a,\eta=d\}&amp;=P\{\xi=a\} P\{\eta=d\}\\ P\{\xi=c,\eta=b\}&amp;=P\{\xi=c\} P\{\eta=b\}\\ P\{\xi=c,\eta=d\}&amp;=P\{\xi=c\} P\{\eta=d\} \end{align*}$$</div><p></p>
<p>至此我们已证得<span class="mathjax-exps">$\xi$</span>与<span class="mathjax-exps">$\eta$</span>独立。</p>
</details>
<p>由上述推导可知，对事件 <span class="mathjax-exps">\(A\)</span> 与 <span class="mathjax-exps">\(B\)</span>，若定义事件相关系数为<br>
</p><div class="mathjax-exps">\[\rho_{AB} = \rho_{1A1B} = \frac{P(AB) - P(A)P(B)}{\sqrt{P(A)P(\bar{A})P(B)P(\bar{B})}}\]</div><p></p>
<p>则 <span class="mathjax-exps">\(A\)</span> 与 <span class="mathjax-exps">\(B\)</span> 独立的充要条件为 <span class="mathjax-exps">\(\rho_{AB} = 0\)</span>.</p>
<p><span class="callout">Corollary</span></p>
<blockquote>
<p><span class="mathjax-exps">\(|P(AB) - P(A)P(B)| \leq \frac{1}{4}\)</span></p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>由<br>
</p><div class="mathjax-exps">\[\rho_{AB} = \rho_{1A1B} = \frac{P(AB) - P(A)P(B)}{\sqrt{P(A)P(\bar{A})P(B)P(\bar{B})}} \leq 1\]</div><p></p>
<p>可得 <span class="mathjax-exps">\(|P(AB) - P(A)P(B)| \leq \sqrt{P(A)P(\bar{A})P(B)P(\bar{B})} \leq \frac{1}{4}\)</span>.</p>
</details>
<h4 id="矩">矩 </h4>
<p><span class="callout">4.2.5 Definition: 原点矩</span></p>
<blockquote>
<p>对正整数<span class="mathjax-exps">$k$</span>，称<br>
</p><div class="mathjax-exps">$$m_k = E\xi^k$$</div><p></p>
<p>为<span class="mathjax-exps">$k$</span>阶原点矩。数学期望是一阶原点矩。<br>
由于<span class="mathjax-exps">$|\xi|^{k-1} \leqslant 1+|\xi|^k$</span>，因此若<span class="mathjax-exps">$k$</span>阶矩存在，则所有低阶矩都存在。</p>
</blockquote>
<p><span class="callout">4.2.6 Definition: 中心矩</span></p>
<blockquote>
<p>对正整数<span class="mathjax-exps">$k$</span>，称<br>
</p><div class="mathjax-exps">$$c_k = E(\xi-E\xi)^k$$</div><p></p>
<p>为<span class="mathjax-exps">$k$</span>阶中心矩。方差是2阶中心矩。</p>
</blockquote>
<p>由于</p>
<p></p><div class="mathjax-exps">$$\begin{align*} c_k = E(\xi-E\xi)^k &amp;= \sum_{i=0}^k \binom{k}{i}(-E\xi)^{k-i} E\xi^i\\ &amp;= \sum_{i=0}^k \binom{k}{i}(-m_1)^{k-i} m_i \end{align*}$$</div><p></p>
<p>故中心矩可通过原点矩来表达，反之，<br>
</p><div class="mathjax-exps">\[\begin{align*}       m_k &amp;= E\xi^k = E\left[\left(\xi - m_1\right) + m_1\right]^k \\ &amp;= \sum_{i=0}^k \binom{k}{i} E\left(\xi - m_1\right)^{k-i} m_1^i = \sum_{i=0}^k \binom{k}{i} c_{k-i} m_1^i \end{align*}\]</div><p></p>
<p>因此当已知数学期望之后，原点矩也可以通过中心矩给出。</p>
<p><span class="callout">Example: 正态分布的矩</span></p>
<p>设<span class="mathjax-exps">$\xi$</span>为正态随机变量，其密度函数为<br>
</p><div class="mathjax-exps">$$p(x)=\frac{1}{\sqrt{2\pi\sigma}} e^{-x^2/\left(2\sigma^2\right)}$$</div><p></p>
<p>因此<span class="mathjax-exps">$E\xi=0$</span>，故</p>
<p></p><div class="mathjax-exps">$$m_k=c_k=E\xi^k=\int_{-\infty}^{\infty} x^k\frac{1}{\sqrt{2\pi\sigma}} e^{-x^2/\left(2\sigma^2\right)} d x$$</div><p></p>
<p>显然，<span class="mathjax-exps">$k$</span>为奇数时，<span class="mathjax-exps">$c_k=0$</span>；<span class="mathjax-exps">$k$</span>为偶数时，</p>
<p></p><div class="mathjax-exps">$$\begin{align*} c_k&amp;=\sqrt{\frac{2}{\pi}}\int_0^{\infty}\frac{x^k}{\sigma}{e^{-\frac{x^2}{2\sigma^2}}~d x}=\sqrt{\frac{2}{\pi}}\sigma^k\cdot 2^{\frac{k-1}{2}}\int_0^{\infty} z^{\frac{k-1}{2}} e^{-z}~d z \\ &amp;=\sqrt{\frac{2}{\pi}}\sigma^k 2^{\frac{k-1}{2}}\Gamma\left(\frac{k+1}{2}\right)=\sigma^k(k-1)(k-3)\cdots 3\cdot 1 \end{align*}$$</div><p></p>
<p>特别地<br>
</p><div class="mathjax-exps">$$c_4=3\sigma^4$$</div><p></p>
<h4 id="分位数">分位数 </h4>
<p><span class="callout">4.2.7 Definition: 分位数</span></p>
<blockquote>
<p>对<span class="mathjax-exps">$0 &lt; p &lt; 1$</span>，若<br>
</p><div class="mathjax-exps">$$F(x_p) \leqslant p \leqslant F(x_p+0)$$</div><p></p>
<p>则称<span class="mathjax-exps">$x_p$</span>为分布函数<span class="mathjax-exps">$F(x)$</span>的<span class="mathjax-exps">$p$</span>分位数。</p>
</blockquote>
<p>由于 <span class="mathjax-exps">$F(x)$</span> 可能不是严格单调递增的，所以不采用 <span class="mathjax-exps">$F(x_p) = p$</span> 来定义分位数。</p>
<h3 id="条件数学期望">条件数学期望 </h3>
<p><span class="callout">4.2.8 Definition: 条件数学期望</span></p>
<blockquote>
<p>在<span class="mathjax-exps">$\xi=x$</span>的条件下，<span class="mathjax-exps">$\eta$</span>的条件数学期望定义为<br>
</p><div class="mathjax-exps">$$E\{\eta | \xi = x\} = \int_{-\infty}^{\infty} yp(y | x) dy$$</div><p></p>
</blockquote>
<p>条件数学期望在预测问题(拟合)中有重要应用。<br>
考虑随机变量 <span class="mathjax-exps">$\xi$</span> 与 <span class="mathjax-exps">$\eta$</span>，若需要寻找 <span class="mathjax-exps">$h(\xi )$</span>，使得 <span class="mathjax-exps">$E(\eta - h(\xi ))^2$</span> 最小。<br>
</p><div class="mathjax-exps">\[\begin{align*} E[\eta - h(\xi)]^2 &amp;= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} [y - h(x)]^2 p(x,y) \, dx \, dy\\ &amp;= \int_{-\infty}^{\infty} p_1(x) \left\{ \int_{-\infty}^{\infty} [y - h(x)]^2 p(y \mid x) \, dy \right\} \, dx \end{align*}\]</div><p></p>
<p>由<a href="#Var-1">方差的性质</a>可知，当 <span class="mathjax-exps">$h(x) = E(\eta \mid \xi = x)$</span> 时，<span class="mathjax-exps">$E[\eta - h(\xi)]^2$</span> 最小。称 <span class="mathjax-exps">$E(\eta \mid \xi = x)$</span> 为 <span class="mathjax-exps">$\eta$</span> 关于 <span class="mathjax-exps">$\xi = x$</span> 的回归。</p>
<p><span class="callout">Theorem: 重期望公式</span></p>
<blockquote>
<p>记<span class="mathjax-exps">\(E\{\eta|\xi\}\)</span> 为 <span class="mathjax-exps">\(\xi\)</span> 的如下函数：当 <span class="mathjax-exps">\(\xi = x\)</span> 时，它取值 <span class="mathjax-exps">\(E\{\eta|\xi = x\}\)</span>。显然<span class="mathjax-exps">\(E\{\eta|\xi\}\)</span> 是随机变量，且<span class="mathjax-exps">\(E\eta = E[E\{\eta \mid \xi\}]\)</span>。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p></p><div class="mathjax-exps">$$\begin{align*} E[E\{\eta\mid\xi\}] &amp;= \int_{-\infty}^{\infty} E\left\{\eta\mid\xi=x\right\} p_{1}(x) d x \\ &amp;=\int_{-\infty}^{\infty}\left[\int_{-\infty}^{\infty} y p(y\mid x) d y\right] p_{1}(x) d x\\ &amp;=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} y p(x, y) d x d y = E\eta \end{align*}$$</div><p></p>
</details>
<p>一般情况下 <span class="mathjax-exps">$E\{\eta \mid \xi = x\}$</span> 不易求出，则对 <span class="mathjax-exps">$h(x)$</span> 的拟合可以采用线性函数，即 <span class="mathjax-exps">$L(x) = ax + b$</span>。<br>
求下列误差函数的最小值，即<br>
</p><div class="mathjax-exps">\[(a,b) =  \arg \min e(a, b) = E[\eta - (a + b\xi)]^2\]</div><p></p>
<p>把 <span class="mathjax-exps">\(e(a, b)\)</span> 对 <span class="mathjax-exps">\(a, b\)</span> 求偏导数并令它们等于 0 ，得到<br>
</p><div class="mathjax-exps">\[\begin{align*} &amp; 2 E[\eta - (a + b\xi)] = 0 \\ &amp; 2 E[(\eta - (a + b\xi))\xi] = 0 \end{align*}\]</div><p></p>
<p>整理后变成<br>
</p><div class="mathjax-exps">\[\begin{align*} &amp; a + b\mu_1 = \mu_2 \\ &amp; a\mu_1 + b E\xi^2 = E\xi\eta \end{align*}\]</div><p></p>
<p>因此解得<br>
</p><div class="mathjax-exps">\[\begin{align*} &amp; a = \mu_2 - b\mu_1, \quad b = \frac{\operatorname{cov}(\xi, \eta)}{\sigma_1^2} = \rho \cdot \frac{\sigma_2}{\sigma_1} \end{align*}\]</div><p></p>
<p>最佳线性预测为<br>
</p><div class="mathjax-exps">\[L(x) = \mu_2 + \rho \frac{\sigma_2}{\sigma_1} (x - \mu_1)\]</div><p></p>
<p>我们称为 <span class="mathjax-exps">\(\eta\)</span> 关于 <span class="mathjax-exps">\(\xi\)</span> 的线性回归。这个结果与 <span class="mathjax-exps">\(E\{\eta \mid \xi = x\}\)</span> 一般是不同的，但是在 <span class="mathjax-exps">\((\xi, \eta)\)</span> 是二元正态分布的场合两者是重合的，所以在正态分布场合，最佳预测是线性预测，这是一个十分重要的结果。</p>
<p>进一步，我们还可以计算最佳线性预测的均方误差.</p>
<p></p><div class="mathjax-exps">\[\begin{aligned}     E[\eta - L(\xi)]^2 &amp;= E[\eta - \mu_2 - b(\xi - \mu_1)]^2 \\     &amp;= \sigma_2^2 + b^2\sigma_1^2 - 2b\operatorname{cov}(\xi, \eta)\\ &amp;= \sigma_2^2 - \frac{\operatorname{cov}^2(\xi, \eta)}{\sigma_1^2} = \sigma_2^2(1 - \rho^2) \end{aligned}\]</div><p></p>
<p>因此预测误差同 <span class="mathjax-exps">\(\eta\)</span> 的方差有关，也同 <span class="mathjax-exps">\(\xi\)</span> 与 <span class="mathjax-exps">\(\eta\)</span> 的相关系数有关，特别当 <span class="mathjax-exps">\(|\rho| = 1\)</span> 时（这时 <span class="mathjax-exps">\(\xi\)</span> 与 <span class="mathjax-exps">\(\eta\)</span> 有线性关系），预测误差为 0，也就是说，可以完全准确地进行线性预测。从这个讨论再次看出，相关系数反映了 <span class="mathjax-exps">\(\xi\)</span> 与 <span class="mathjax-exps">\(\eta\)</span> 线性联系的程度。</p>
<p>最佳线性预测理论中的另一个重要事实是：预测值 <span class="mathjax-exps">\(\hat{\eta} = L(\xi)\)</span> 与残差 <span class="mathjax-exps">\(\eta - \hat{\eta}\)</span> 是不相关的。证明如下：</p>
<details open="">
    <summary>Proof:</summary>
<p>由于<br>
</p><div class="mathjax-exps">\[\hat{\eta} = L(\xi) = \mu_2 + \rho \frac{\sigma_2}{\sigma_1} (\xi - \mu_1)\]</div><p></p>
<p>因此<br>
</p><div class="mathjax-exps">$$\begin{gathered} E\hat{\eta} = \mu_2 \\ E(\eta - \hat{\eta}) = 0 \end{gathered}$$</div><p></p>
<p>这样一来<br>
</p><div class="mathjax-exps">$$\begin{align*} \operatorname{cov}(\hat{\eta}, \eta - \hat{\eta}) &amp;= E[(\hat{\eta} - \mu_2)(\eta - \hat{\eta})] \\ &amp;= E\left\{\rho \frac{\sigma_2}{\sigma_1} (\xi - \mu_1)[(\eta - \mu_2) - \rho \frac{\sigma_2}{\sigma_1} (\xi - \mu_1)]\right\} \\ &amp;= \rho \frac{\sigma_2}{\sigma_1} (\rho \sigma_1 \sigma_2 - \rho \frac{\sigma_2}{\sigma_1} \sigma_1^2) = 0 \end{align*}$$</div><p></p>
<p>这个事实可以解释为：残差中已不再包含对预测 <span class="mathjax-exps">\(\eta\)</span> 有用的知识。因此观察值 <span class="mathjax-exps">\(\eta\)</span> 被分解为两个不相关的随机变量之和：<br>
</p><div class="mathjax-exps">\[\eta = \hat{\eta} + (\eta - \hat{\eta})\]</div><p></p>
</details>
<h3 id="熵与信息">熵与信息 </h3>
<h3 id="母函数">母函数 </h3>
<h4 id="母函数的概念">母函数的概念 </h4>
<p><span class="callout">4.4.1 Definition: 随机变量的母函数定义</span></p>
<blockquote>
<p>若随机变量 <span class="mathjax-exps">$\xi$</span> 取非负整数值，且相应的分布列为</p>
</blockquote>
<table>
<thead>
<tr>
<th><span class="mathjax-exps">$\xi$</span></th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>...</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="mathjax-exps">$P$</span></td>
<td><span class="mathjax-exps">$p_0$</span></td>
<td><span class="mathjax-exps">$p_1$</span></td>
<td><span class="mathjax-exps">$p_2$</span></td>
<td>...</td>
</tr>
</tbody>
</table>
<blockquote>
<p>则称<br>
</p><div class="mathjax-exps">$$P(s)=\sum_{k=0}^{\infty} p_k s^k$$</div><p></p>
<p>为 <span class="mathjax-exps">$\xi$</span> 的母函数(generating function)。</p>
</blockquote>
<p>下面给出常见分布的母函数。<br>
<span class="callout">4.4.5 Example: 二项分布的母函数</span></p>
<blockquote>
<p></p><div class="mathjax-exps">$$P(s)=\sum_{k=0}^n\binom{n}{k}\cdot p^kq^{n-k}s^k=(q+ps)^n$$</div><p></p>
</blockquote>
<p><span class="callout">4.4.7 Example: 泊松分布的母函数</span></p>
<blockquote>
<p></p><div class="mathjax-exps">$$P(s)=\sum_{k=0}^{\infty}\frac{\lambda^k}{k!} e^{-\lambda}s^k=e^{-\lambda}\cdot e^{\lambda s}=e^{\lambda(s-1)}$$</div><p></p>
</blockquote>
<p><span class="callout">4.4.8 Example: 几何分布的母函数</span></p>
<blockquote>
<p></p><div class="mathjax-exps">$$P(s)=\sum_{k=1}^{\infty} q^{k-1} p s^k=p s\sum_{k=1}^{\infty}(q s)^{k-1}=\frac{p s}{1-q s}$$</div><p></p>
</blockquote>
<p>母函数的性质：<br>
1.母函数和分布列是一一对应的。<br>
设概率分布 <span class="mathjax-exps">$\left\{p_k\right\}$</span> 及 <span class="mathjax-exps">$\left\{q_k\right\}$</span> 分别具有母函数 <span class="mathjax-exps">$P(s)$</span> 及 <span class="mathjax-exps">$Q(s)$</span>，而且 <span class="mathjax-exps">$P(s)=Q(s)$</span>，因为 <span class="mathjax-exps">$P(s)$</span> 及 <span class="mathjax-exps">$Q(s)$</span> 都是幂级数，且当 <span class="mathjax-exps">$|s|\leqslant 1$</span> 时收敛，对 <span class="mathjax-exps">$P(s)$</span> 及 <span class="mathjax-exps">$Q(s)$</span> 求导 <span class="mathjax-exps">$k$</span> 次，并令 <span class="mathjax-exps">$s=0$</span>，则得<br>
</p><div class="mathjax-exps">$$k! p_k=P^{(k)}(0)=Q^{(k)}(0)=k! q_k$$</div><p></p>
<p>所以 <span class="mathjax-exps">$p_k=q_k$</span>，即母函数唯一确定分布列。</p>
<p>2.母函数与数字特征的关系。<br>
若 <span class="mathjax-exps">$P(s)=\sum_{k=0}^{\infty} p_k s^k$</span>，即 <span class="mathjax-exps">$P'(s)=\sum_{k=1}^{\infty} k p_k s^{k-1}, P''(s)=\sum_{k=2}^{\infty} k(k-1) p_k s^{k-2}$</span>，这两个级数至少在 <span class="mathjax-exps">$|s|&lt;1$</span> 是收敛的。</p>
<p>当数学期望 <span class="mathjax-exps">$\sum_{k=1}^{\infty} kp_k$</span> 存在时，<span class="mathjax-exps">$P'(1)=\sum_{k=1}^{\infty} kp_k=E\xi$</span>。<br>
当数学期望 <span class="mathjax-exps">$\sum_{k=1}^{\infty} k p_k=\infty$</span> 时，<span class="mathjax-exps">$\lim_{s\rightarrow 1} P'(s)=\infty$</span>。<br>
同样，当方差 <span class="mathjax-exps">$D\xi$</span> 存在时，<span class="mathjax-exps">$E[\xi(\xi-1)]=\sum_{k=2}^{\infty} k(k-1) p_k=P''(1)$</span>。<br>
故 <span class="mathjax-exps">$D\xi=E\xi^2-(E\xi)^2=P''(1)+P'(1)-[P'(1)]^2$</span>。<br>
上述公式是计算数学期望及方差的简便公式。</p>
<h4 id="独立随机变量和的母函数">独立随机变量和的母函数 </h4>
<p>若随机变量 <span class="mathjax-exps">$\xi$</span> 与 <span class="mathjax-exps">$\eta$</span> 相互独立，它们都是整值随机变量，概率分布分别为 <span class="mathjax-exps">$\{a_k\}$</span> 及 <span class="mathjax-exps">$\{b_k\}$</span>，相应的母函数为 <span class="mathjax-exps">$A(s) = \sum_{k=0}^{\infty} a_k s^k$</span> 及 <span class="mathjax-exps">$B(s) = \sum_{k=0}^{\infty} b_k s^k$</span>。显然 <span class="mathjax-exps">$\zeta=\xi+\eta$</span> 也是整值随机变量，若记 <span class="mathjax-exps">$c_r = P(\zeta = r)$</span>，则<br>
</p><div class="mathjax-exps">$$c_r = a_0 b_r + a_1 b_{r-1} + \cdots + a_r b_0$$</div><p></p>
<p>这就是离散卷积公式。<br>
记<br>
</p><div class="mathjax-exps">$$C(s) = \sum_{r=0}^{\infty} c_r s^r$$</div><p></p>
<p>利用母函数在 <span class="mathjax-exps">$|s| \leqslant 1$</span> 的一致收敛性及绝对收敛性，<br>
</p><div class="mathjax-exps">$$A(s) B(s) = \sum_{r=0}^{\infty} \left( \sum_{k=0}^{r} a_k b_{r-k} \right) s^r,$$</div><p></p>
<p>因此<br>
</p><div class="mathjax-exps">$$C(s) = A(s) B(s).$$</div><p></p>
<p>即两个独立随机变量之和的母函数是这两个随机变量的母函数的乘积，这是一个相当重要的性质，由于母函数具有这个性质，因此在研究独立随机变量和的问题时，母函数很适用。</p>
<p>容易把上面结果推广到 <span class="mathjax-exps">$n$</span> 个独立整值随机变量之和的场合。若随机变量 <span class="mathjax-exps">$\xi_1, \xi_2, \cdots, \xi_n$</span> 相互独立，且它们的母函数分别为 <span class="mathjax-exps">$P_1(s), P_2(s), \cdots, P_n(s)$</span>，则 <span class="mathjax-exps">$\xi = \xi_1 + \xi_2 + \cdots + \xi_n$</span> 的母函数为<br>
</p><div class="mathjax-exps">$$P(s) = P_1(s) P_2(s) \cdots P_n(s)$$</div><p></p>
<p>特别当 <span class="mathjax-exps">$\xi_i$</span> 有相同概率分布的场合，<span class="mathjax-exps">$P_i(s) = P_1(s)$</span>，这时<br>
</p><div class="mathjax-exps">$$P(s) = [P_1(s)]^n$$</div><p></p>
<h4 id="随机个随机变量的母函数">随机个随机变量的母函数 </h4>
<h3 id="特征函数">特征函数 </h3>
<p><span class="callout">4.5.1 Definition: 复随机变量</span></p>
<blockquote>
<p>如果 <span class="mathjax-exps">$\xi$</span> 与 <span class="mathjax-exps">$\eta$</span> 都是概率空间 <span class="mathjax-exps">$(\Omega, \mathcal{F}, P)$</span> 上的实值随机变量，则称 <span class="mathjax-exps">$\zeta = \xi + i\eta$</span> 为复随机变量。</p>
</blockquote>
<p><span class="callout">4.5.2 Definition: 复随机变量的数学期望</span></p>
<blockquote>
<p>定义一个复随机变量 <span class="mathjax-exps">$\zeta = \xi + i\eta$</span> 的数学期望为<br>
</p><div class="mathjax-exps">$$E\zeta = E\xi + iE\eta$$</div><p></p>
</blockquote>
<p>从定义知道，对复随机变量的研究本质上是对二维随机向量的研究。例如二维向量 <span class="mathjax-exps">$(\xi_1, \eta_1)$</span> 与 <span class="mathjax-exps">$(\xi_2, \eta_2)$</span> 是独立的，则我们称复随机变量 <span class="mathjax-exps">$\zeta_1 = \xi_1 + i\eta_1$</span> 与 <span class="mathjax-exps">$\zeta_2 = \xi_2 + i\eta_2$</span> 是独立的。<br>
对复随机变量也可以平行于实随机变量建立起一系列结果。例如，若 <span class="mathjax-exps">$\xi_1, \xi_2, \cdots, \xi_n$</span> 是相互独立的，则<br>
</p><div class="mathjax-exps">$$E\xi_1\xi_2\cdots\xi_n = E\xi_1 E\xi_2 \cdots E\xi_n$$</div><p></p>
<p>又如，若 <span class="mathjax-exps">$g(x)$</span> 是一个一元博雷尔可测函数，而 <span class="mathjax-exps">$\eta = g(\xi)$</span>，则成立<br>
</p><div class="mathjax-exps">$$Ee^{ig(\xi)} = \int_{-\infty}^{\infty} e^{itg(x)} dF_\xi(x)$$</div><p></p>
<p>这里使用欧拉公式 <span class="mathjax-exps">$e^{i\theta} = \cos\theta + i\sin\theta$</span>。</p>
<p><span class="callout">4.5.2 Definition: 特征函数</span></p>
<blockquote>
<p>若随机变量 <span class="mathjax-exps">$\xi$</span> 的分布函数为 <span class="mathjax-exps">$F_\xi(x)$</span>，则称<br>
</p><div class="mathjax-exps">$$f_\xi(t)=E e^{i t\xi}=\int_{-\infty}^{\infty} e^{i t x} d F_\xi(x)$$</div><p></p>
<p>为 <span class="mathjax-exps">$\xi$</span> 的特征函数(characteristic function)。</p>
</blockquote>
<p>特征函数是一个实变量的复值函数，由于 <span class="mathjax-exps">$|e^{itx}| = 1$</span>，所以它对一切实数 <span class="mathjax-exps">$t$</span> 都有意义。对于离散型随机变量，若其分布列为 <span class="mathjax-exps">$p_j$</span>，则其特征函数为<br>
</p><div class="mathjax-exps">$$f(t) = \sum_{j=1}^{\infty} p_j e^{itx_j}$$</div><p></p>
<p>特别地，对于整值随机变量，若其母函数为 <span class="mathjax-exps">$P(s)$</span>，则 <span class="mathjax-exps">$f(t) = P(e^{it})$</span>。显然对于常见的分布可以利用上一节的母函数立马得到特征函数。<br>
对于连续型随机变量，若其分布密度函数为 <span class="mathjax-exps">$p(x)$</span>，则其特征函数为<br>
</p><div class="mathjax-exps">$$f(t) = \int_{-\infty}^{\infty} e^{itx} p(x) dx$$</div><p></p>
<p>这时，特征函数是密度函数 <span class="mathjax-exps">$p(x)$</span> 的傅里叶(Fourier)变换。<br>
下面给出常见分布的特征函数。<br>
<span class="callout">4.5.5 Example: 退化分布的特征函数</span></p>
<blockquote>
<p>退化分布 <span class="mathjax-exps">$I_c(x)$</span> 的特征函数为<br>
</p><div class="mathjax-exps">$$f(t)=e^{i c t}$$</div><p></p>
</blockquote>
<p><span class="callout">4.5.6 Example: 二项分布的特征函数</span></p>
<blockquote>
<p>二项分布 <span class="mathjax-exps">$B(n, p)$</span> 的特征函数为<br>
</p><div class="mathjax-exps">$$f(t)=\left(p e^{i t}+q\right)^n$$</div><p></p>
</blockquote>
<p><span class="callout">4.5.7 Example: 泊松分布的特征函数</span></p>
<blockquote>
<p>泊松分布 <span class="mathjax-exps">$P(\lambda)$</span> 的特征函数为<br>
</p><div class="mathjax-exps">$$f(t)=e^{\lambda(e^{i t}-1)}$$</div><p></p>
</blockquote>
<p><span class="callout">4.5.8 Example: <span class="mathjax-exps">$\Gamma$</span> 分布的特征函数</span></p>
<blockquote>
<p><span class="mathjax-exps">$\Gamma$</span> 分布 <span class="mathjax-exps">$\Gamma(r,\lambda)$</span> 的特征函数为<br>
</p><div class="mathjax-exps">$$\begin{align*} f(t)&amp;=\int_0^{\infty} e^{i t x}\frac{\lambda^r}{\Gamma(r)} x^{r-1} e^{-\lambda x} d x \\ &amp;=\int_0^{\infty}\frac{\lambda^r}{\Gamma(r)} x^{r-1} e^{-\left(\lambda -{i t}\right) x} d x \\ &amp;=\left(1-\frac{i t}{\lambda}\right)^{-r} \end{align*}$$</div><p></p>
</blockquote>
<p>最后一个等式需要用到 <span class="mathjax-exps">$\Gamma$</span> 函数的性质：<br>
</p><div class="mathjax-exps">$$\int_0^{\infty} x^{r-1} e^{-\alpha x} d x = \frac{\Gamma(r)}{\alpha^r}$$</div><p></p>
<p><span class="callout">4.5.9 Example: 指数分布的特征函数</span></p>
<blockquote>
<p>特别地，参数为 <span class="mathjax-exps">$\lambda$</span> 的指数分布 <span class="mathjax-exps">$\operatorname{Exp}(\lambda)$</span>，即 <span class="mathjax-exps">$\Gamma(1,\lambda)$</span> 的特征函数为<br>
</p><div class="mathjax-exps">$$f(t)=\left(1-\frac{i t}{\lambda}\right)^{-1}$$</div><p></p>
</blockquote>
<p><span class="callout">4.5.10 Example: <span class="mathjax-exps">$\chi^2$</span> 分布的特征函数</span></p>
<blockquote>
<p>同样地，参数 <span class="mathjax-exps">$n$</span> 的 <span class="mathjax-exps">$\chi^2$</span> 分布，即 <span class="mathjax-exps">$\Gamma\left(\frac{n}{2},\frac{1}{2}\right)$</span> 的特征函数为<br>
</p><div class="mathjax-exps">$$f(t)=(1-2 i t)^{-\frac{n}{2}}$$</div><p></p>
</blockquote>
<p><span class="callout">4.5.* Example: 正态分布的特征函数</span></p>
<blockquote>
<p>正态分布 <span class="mathjax-exps">\(N(\mu, \sigma^2)\)</span> 的特征函数为<br>
</p><div class="mathjax-exps">\[f(t) = \exp\left\{i\mu t - \frac{1}{2}\sigma^2 t^2\right\}\]</div><p></p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p></p><div class="mathjax-exps">$$\begin{align*} f(t) &amp;= \int_{-\infty}^{+\infty}  \frac{1}{\sigma\sqrt{2\pi}} \exp \left\{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2 \right\} \exp \left\{itx \right\} d x  \\ &amp;= \int_{-\infty}^{+\infty}  \frac{1}{\sigma\sqrt{2\pi}} \exp \left\{ -\frac{1}{2 \sigma ^2} \left( x^2 - 2 \mu x + \mu ^2 - 2 \sigma ^2 itx \right) \right\} d x \\ &amp;= \int_{-\infty}^{+\infty}  \frac{1}{\sigma\sqrt{2\pi}} \exp \left\{ -\frac{1}{2 \sigma ^2} \left[ x - (\mu + \sigma ^2 it) \right]^2 \right\} \exp \left\{ i \mu t - \frac{1}{2} \sigma ^2 t^2 \right\} dx \\ &amp;= \exp \left\{ i \mu t - \frac{1}{2} \sigma ^2 t^2 \right\} \end{align*}$$</div><p></p>
</details>
<p>下面讨论特征函数的性质。</p>
<ol>
<li>
<p><span class="mathjax-exps">$f(0) = 1, |f(t)| \leqslant 1, f(-t) = \overline{f(t)}$</span>。</p>
</li>
<li>
<p>特征函数在 <span class="mathjax-exps">$(-\infty, \infty)$</span> 上一致连续。</p>
</li>
<li>
<p>对于任意的正整数 <span class="mathjax-exps">$n$</span> 及任意实数 <span class="mathjax-exps">$t_1, t_2, \cdots, t_n$</span> 及复数 <span class="mathjax-exps">$\lambda_1, \lambda_2, \cdots, \lambda_n$</span>，成立<br>
</p><div class="mathjax-exps">$$\sum_{k=1}^{n} \sum_{j=1}^{n} f(t_k - t_j) \lambda_k \overline{\lambda_j} \geq 0$$</div><p></p>
</li>
<li>
<p>两个相互独立的随机变量之和的特征函数等于它们的特征函数之积。一般的，若 <span class="mathjax-exps">$n$</span> 个独立整值随机变量之和的特征函数为这 <span class="mathjax-exps">$n$</span> 个随机变量的特征函数之积。</p>
</li>
<li>
<p>设随机变量 <span class="mathjax-exps">$\xi$</span> 有 n 阶矩存在，则它的特征函数可微分 n 次，且当 <span class="mathjax-exps">$k \leqslant n$</span> 时：<span class="mathjax-exps">$f^{(k)}(0) = i^k E\xi^k$</span>。<br>
该性质提供了计算随机变量的矩的一种方法。</p>
</li>
<li>
<p>若随机变量有 n 阶矩存在，则它的特征函数可作如下展开：<br>
</p><div class="mathjax-exps">$$f(t) = 1 + (it)E\xi + \frac{(it)^2}{2!}E\xi^2 + \cdots + \frac{(it)^n}{n!}E\xi^n + o(t^n)$$</div><p></p>
</li>
<li>
<p>设 <span class="mathjax-exps">$\eta = a\xi + b$</span>，这里 <span class="mathjax-exps">$a, b$</span> 为常数，则<br>
</p><div class="mathjax-exps">$$f_\eta(t) = e^{ibt} f_\xi(at)$$</div><p></p>
</li>
</ol>
<details open="">
    <summary>Proof:</summary>
<p>参见概率论基础第三版p249</p>
</details>
<p><span class="callout">4.5.2 Theorem: 唯一性定理</span></p>
<blockquote>
<p>分布函数由其特征函数唯一决定。</p>
</blockquote>
<h4 id="分布函数的再生性">分布函数的再生性 </h4>
<p>利用特征函数，可以很方便的研究分布的再生性，即可加性。</p>
<p><span class="callout">4.5.26 Example: 二项分布的卷积</span></p>
<blockquote>
<p>若 <span class="mathjax-exps">$\xi_1 \sim B(m, p), \xi_2 \sim  B(n, p)$</span>，而且 <span class="mathjax-exps">$\xi_1$</span> 与 <span class="mathjax-exps">$\xi_2$</span> 独立，则 <span class="mathjax-exps">$\eta=\xi_1+\xi_2 \sim B(m+n, p)$</span>。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>事实上 <span class="mathjax-exps">$f_{\xi_1}(t)=\left(p e^{i t}+q\right)^m, f_{\xi_2}(t)=\left(p e^{i t}+q\right)^n$</span>，由性质 4 知<br>
</p><div class="mathjax-exps">$$f_n(t)=\left(p e^{i t}+q\right)^{m+n}$$</div><p></p>
<p>因此由唯一性定理知 <span class="mathjax-exps">$\eta$</span> 服从 <span class="mathjax-exps">$B(m+n, p)$</span>。<br>
简记作<br>
</p><div class="mathjax-exps">$$B(n_1, p) * B(n_2, p) = B(n_1+n_2, p)$$</div><p></p>
</details>
<p><span class="callout">4.5.27 Example: 泊松分布的卷积</span></p>
<blockquote>
<p>若 <span class="mathjax-exps">$\xi_1 \sim P(\lambda_1), \xi_2 \sim P(\lambda_2)$</span>，而且 <span class="mathjax-exps">$\xi_1$</span> 与 <span class="mathjax-exps">$\xi_2$</span> 独立，则 <span class="mathjax-exps">$\eta=\xi_1+\xi_2 \sim P(\lambda_1+\lambda_2)$</span>。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>事实上<br>
</p><div class="mathjax-exps">$$f_{\xi_1}(t) = e^{\lambda_1(e^{it} - 1)}, \quad f_{\xi_2}(t) = e^{\lambda_2(e^{it} - 1)}$$</div><p></p>
<p>简记作<br>
</p><div class="mathjax-exps">$$P(\lambda_1) * P(\lambda_2) = P(\lambda_1 + \lambda_2)$$</div><p></p>
</details>
<p><span class="callout">4.5.28 Example: 正态分布的卷积</span></p>
<blockquote>
<p>若 <span class="mathjax-exps">$\xi_1 \sim N(\mu_1, \sigma_1^2), \xi_2 \sim N(\mu_2, \sigma_2^2)$</span>，而且 <span class="mathjax-exps">$\xi_1$</span> 与 <span class="mathjax-exps">$\xi_2$</span> 独立，则 <span class="mathjax-exps">$\eta=\xi_1+\xi_2 \sim N(\mu_1+\mu_2, \sigma_1^2+\sigma_2^2)$</span>。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>事实上<br>
</p><div class="mathjax-exps">$$f_{\xi_1}(t) = e^{i\mu_1 t - \frac{1}{2}\sigma_1^2 t^2}, \quad f_{\xi_2}(t) = e^{i\mu_2 t - \frac{1}{2}\sigma_2^2 t^2}$$</div><p></p>
<p>简记作<br>
</p><div class="mathjax-exps">$$N(\mu_1, \sigma_1^2) * N(\mu_2, \sigma_2^2) = N(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)$$</div><p></p>
</details>
<p><span class="callout">4.5.29 Example: gamma分布的卷积</span></p>
<blockquote>
<p>若 <span class="mathjax-exps">$\xi_1 \sim \Gamma(r_1, \lambda), \xi_2 \sim \Gamma(r_2, \lambda)$</span>，而且 <span class="mathjax-exps">$\xi_1$</span> 与 <span class="mathjax-exps">$\xi_2$</span> 独立，则 <span class="mathjax-exps">$\eta=\xi_1+\xi_2 \sim \Gamma(r_1+r_2, \lambda)$</span>。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>事实上<br>
</p><div class="mathjax-exps">$$\begin{align*} &amp; f_{\xi_1}(t) = \left(1 - \frac{it}{\lambda}\right)^{-r_1}, \quad f_{\xi_2}(t) = \left(1 - \frac{it}{\lambda}\right)^{-r_2} \\ &amp; f_\eta (t) = \left(1 - \frac{it}{\lambda}\right)^{-(r_1 + r_2)} \end{align*}$$</div><p></p>
<p>简记作<br>
</p><div class="mathjax-exps">$$\Gamma(r_1, \lambda) * \Gamma(r_2, \lambda) = \Gamma(r_1 + r_2, \lambda)$$</div><p></p>
<p>特别地，<span class="mathjax-exps">$\chi_n^2$</span> 分布即为 <span class="mathjax-exps">$\Gamma\left(\frac{n}{2}, \frac{1}{2}\right)$</span>，也具有再生性：<br>
</p><div class="mathjax-exps">$$\chi_m^2 * \chi_n^2 = \chi_{m+n}^2$$</div><p></p>
</details>
<h4 id="多元特征函数">多元特征函数 </h4>
<h3 id="多元正态分布">多元正态分布 </h3>
<p>最后一步推导是通过<strong>伽马函数的性质</strong>来完成的，以下是详细的过程：</p>
<ol>
<li>
<p><strong>整理被积表达式：</strong></p>
<p>我们将积分表达式化简：<br>
</p><div class="mathjax-exps">$$f(t) = \int_0^{\infty} \frac{\lambda^r}{\Gamma(r)} x^{r-1} e^{-\lambda\left(1-\frac{i t}{\lambda}\right) x} d x$$</div><br>
将指数部分重新表示为：<br>
<div class="mathjax-exps">$$e^{-\lambda\left(1-\frac{i t}{\lambda}\right) x} = e^{-a x}, \quad \text{其中 } a = \lambda\left(1 - \frac{i t}{\lambda}\right) = \lambda - i t.$$</div><p></p>
<p>整个积分变为：<br>
</p><div class="mathjax-exps">$$f(t) = \frac{\lambda^r}{\Gamma(r)} \int_0^{\infty} x^{r-1} e^{-a x} d x, \quad \text{其中 } a = \lambda - i t.$$</div><p></p>
</li>
<li>
<p><strong>结合伽马函数的定义：</strong></p>
<p>伽马函数的定义为：<br>
</p><div class="mathjax-exps">$$\Gamma(r) = \int_0^{\infty} x^{r-1} e^{-x} d x.$$</div><br>
如果将 <span class="mathjax-exps">$x$</span> 替换为 <span class="mathjax-exps">$x/a$</span>，则积分可以写为：<br>
<div class="mathjax-exps">$$\int_0^{\infty} x^{r-1} e^{-a x} d x = \frac{\Gamma(r)}{a^r}.$$</div><p></p>
<p>将这一性质代入 <span class="mathjax-exps">$f(t)$</span> 的积分：<br>
</p><div class="mathjax-exps">$$f(t) = \frac{\lambda^r}{\Gamma(r)} \cdot \frac{\Gamma(r)}{a^r}.$$</div><p></p>
</li>
<li>
<p><strong>整理结果：</strong></p>
<p>消去 <span class="mathjax-exps">$\Gamma(r)$</span>：<br>
</p><div class="mathjax-exps">$$f(t) = \frac{\lambda^r}{a^r}.$$</div><br>
代入 <span class="mathjax-exps">$a = \lambda - i t$</span>：<br>
<div class="mathjax-exps">$$f(t) = \left(\lambda - i t\right)^{-r}.$$</div><p></p>
<p>再将 <span class="mathjax-exps">$a$</span> 表达为 <span class="mathjax-exps">$\lambda\left(1 - \frac{i t}{\lambda}\right)$</span>，结果化简为：<br>
</p><div class="mathjax-exps">$$f(t) = \left(1 - \frac{i t}{\lambda}\right)^{-r}.$$</div><p></p>
</li>
</ol>
<h3 id="总结">总结 </h3>
<p>关键在于：</p>
<ol>
<li>将积分中指数部分改写为 <span class="mathjax-exps">$e^{-a x}$</span> 的形式；</li>
<li>利用伽马函数性质 <span class="mathjax-exps">$\int_0^{\infty} x^{r-1} e^{-a x} d x = \frac{\Gamma(r)}{a^r}$</span>。</li>
</ol>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>