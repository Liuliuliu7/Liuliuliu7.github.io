---
html:
  embed_local_images: true
export_on_save:
  html: true
---
[toc]
<button id="toggleProofs">Toggle Proofs</button>
<script>
  document.getElementById('toggleProofs').addEventListener('click', function() {
    var details = document.querySelectorAll('details > summary');
    for (var i = 0; i < details.length; i++) {
      if (details[i].textContent.includes('Proof')) {
        details[i].parentElement.open = !details[i].parentElement.open;
      }
    }
  });
</script>

#### 第二章 线性映射

##### *2.1.2 Definition: 单射,满射,双射*

> 设$V$和$W$是两个非空集合，$f$是$V$到$W$的一个映射。若对任意$x_1, x_2 \in V$，当$x_1 \neq x_2$时有$f(x_1) \neq f(x_2)$，则称$f$是$V$到$W$的单映射（简称单射）；若对任意$y \in W$都有一个元素$x \in V$使得$f(x) = y$（即$R(f) = W$），则称$f$是$V$到$W$的满映射（简称满射）；若映射$f$既是单映射又是满映射，则称$f$是$V$到$W$的一一映射或双映射（简称双射）。

##### *2.1.4 Definition: 映射积*
> 设$V_1, V_2$和$V_3$是三个非空集合，并设$f_1$是$V_1$到$V_2$的一个映射，$f_2$是$V_2$到$V_3$的一个映射。由$f_1$和$f_2$确定的$V_1$到$V_3$的映射$f: x \rightarrow f(f_1(x)), x \in V_1$，称为映射$f_1$和$f_2$的乘积，记为$f_3 = f_2 \cdot f_1$，或简写为$f = f_2 f_1$。

##### *2.1.5 Definition: 逆映射*
>设有映射$f_1: V \rightarrow W$，若存在映射$f_2: W \rightarrow V$使得$f_2 \cdot f_1 = I_V$和$f_1 \cdot f_2 = I_W$，其中$I_V: x \rightarrow x, x \in V$为$V$上的恒等映射，$I_W$是$W$上的恒等映射。我们称$f_2$为$f_1$的逆映射，记为$f_1'$。若映射$f_1$有逆映射，则称$f_1$为可逆映射。

##### *2.2.1 Definition: 线性映射* 
> 设 $V$ 和 $W$ 是数域 $F$ 上的线性空间，如果映射 $T: V \to W$ 满足下述性质：
> (1) 可加性：对任意 $x, y \in V, T(x + y) = T(x) + T(y)$;
> (2) 齐次性：对任意 $x \in V, \lambda \in F, T(\lambda x) = \lambda T(x)$;
> 则称 $T$ 为 $V$ 到 $W$ 上的线性映射。特别地，当 $V = W$ 时，映射 $T: V \to V$ 称为 $V$ 上的线性变换（或线性算子）。

##### *2.2.5 Example: 正交投影变换*
> 设向量组 $\alpha_1,\cdots,\alpha_p$ 是 $W$ 的一组标准正交基，则 $V$ 中任一向量 $x$ 在 $W$ 上的正交投影为
\[ \text{ Proj}_{w} x=\left(x,\alpha_1\right)\alpha_1+\cdots+\left(x,\alpha_p\right)\alpha_p \]因此，
\[ T(x)=\sum_{i=1}^p\left(x,\alpha_i\right)\alpha_i \]那么，对任意向量 $x, y\in V$ 和 $\lambda,\mu\in F$ 有
\[ \begin{align*} T(\lambda x+\mu y)&=\sum_{i=1}^p\left(\lambda x+\mu y,\alpha_i\right)\alpha_i\\ &=\lambda\sum_{i=1}^p\left(x,\alpha_i\right)\alpha_i+\mu\sum_{i=1}^p\left(y,\alpha_i\right)\alpha_i\\ &=\lambda T(x)+\mu T(y)\end{align*} \] 综上可知，映射 $T$ 是 $V$ 上的线性变换。

##### *2.2.1 Corollary* 
> 设 $V$ 和 $W$ 是数域 $F$ 上的线性空间，$T: V \to W$ 是线性映射, 若$\alpha  _1, \cdots, \alpha  _n $
> (1) $T(\sum_{i=1}^{n} \lambda_i \alpha_i) = \sum_{i=1}^{n} \lambda_i T(\alpha_i)$;
> (2) $T(0) = 0$;
> (3) $T(-\alpha) = -T(\alpha)$, $\forall \alpha \in V$;
> (4) 若 $\alpha  _1, \cdots, \alpha  _n $ 线性相关，则 $T(\alpha  _1), \cdots, T(\alpha  _n )$ 也线性相关;
> (5) 若$T(\alpha  _1), \cdots, T(\alpha  _n )$  线性无关，则  $\alpha  _1, \cdots, \alpha  _n $也线性无关。

<details open>
  <summary>Proof:</summary>

(1) 由线性映射的定义显然可得.  
(2) $T(0) = T(0\cdot 0) = 0\cdot T(0) = 0 $. 
(3) $T(-\alpha) = T(-1\cdot \alpha) = -1\cdot T(\alpha) = -T(\alpha)$.
(4) 由 (5)显然可得.
(5) 若$k_1T(\alpha  _1),+ \cdots,+ k_nT(\alpha  _n ) = 0$ 只在$k_1 = \cdots = k_n = 0$时成立, 则$T(k_1 \alpha_1+ \cdots+ k_n\alpha  _n)=0$ 也只在$k_1 = \cdots = k_n = 0$成立, 若 $\alpha  _1, \cdots, \alpha  _n $ 线性相关,  则存在不全为0的$k_1, \cdots, k_n$使得$k_1\alpha  _1 + \cdots + k_n\alpha  _n = 0$, 则 $T(k_1\alpha  _1 + \cdots + k_n\alpha  _n) = 0$ 且不全为0, 与假设矛盾, 故 $\alpha  _1, \cdots, \alpha  _n $ 线性无关. 反之亦然.
</details>

##### *2.2.2 Theorem: <span id="them2.2.2">无关向量的映射</span>*
> 设 $T: V \to W$ 是线性映射, 当且仅当$T$是单射时，$T$将线性无关的向量映为线性无关的向量.
{注}: $\dim {V} \le \dim {W}$

<details open>
  <summary>Proof:</summary> 

充分性。设 $\alpha_1,\cdots,\alpha_p$ 是 $V$ 中一组线性无关向量，则对任一不全为零的数组 $k_1,\cdots, k_p\in F$，有 $k_1\alpha_1+\cdots+k_p\alpha_p\neq\theta$。由于 $T$ 是单射且 $T(\theta)=\theta$，从而
\[ T\left(k_1\alpha_1+\cdots+k_p\alpha_p\right)=k_1 T\left(\alpha_1\right)+\cdots+k_p T\left(\alpha_p\right)\neq\theta \] 上式说明 $T\left(\alpha_1\right),\cdots, T\left(\alpha_p\right)$ 是 $W$ 的一组线性无关向量。
必要性。设 $\zeta_1,\cdots,\zeta_n$ 是 $V$ 中一组基，则 $V$ 中任意向量 $\alpha$ 和 $\beta$ 可表示为
\[ \alpha=a_1\zeta_1+\cdots+a_n\zeta_n,\quad\beta=b_1\zeta_1+\cdots+b_n\zeta_n \] 式中，$a=\left[a_1,\cdots, a_n\right]^T$ 和 $b=\left[b_1,\cdots, b_n\right]^T$ 分别是向量 $\alpha$ 和 $\beta$ 在基 $\zeta_1,\cdots,\zeta_n$ 下的坐标。于是
\[ \begin{gathered} T(\alpha)=a_1 T\left(\zeta_1\right)+\cdots+a_n T\left(\zeta_n\right)\\ T(\beta)=b_1 T\left(\zeta_1\right)+\cdots+b_n T\left(\zeta_n\right)\end{gathered} \] 且有
\[ T(\alpha)-T(\beta)=\left(a_1-b_1\right) T\left(\zeta_1\right)+\cdots+\left(a_n-b_n\right) T\left(\zeta_n\right) \] 当 $\alpha\neq\beta$ 时，若有 $T(\alpha)=T(\beta)$，则根据上式得
\[ \left(a_1-b_1\right) T\left(\zeta_1\right)+\cdots+\left(a_n-b_n\right) T\left(\zeta_n\right)=\theta \] 由于 $T\left(\zeta_1\right),\cdots, T\left(\zeta_n\right)$ 线性无关，故 $a_i=b_i, i=1,\cdots, n$，即 $a=b$。由于 $\alpha\neq\beta$，故其坐标 $a\neq b$。因此，当 $\alpha\neq\beta$ 时，$T(\alpha)\neq T(\beta)$。这表明映射 $T$ 是单射。证毕。
</details>

##### *2.2.2 Definition: 线性映射的加法和数乘*
> 设 $V$ 和 $W$ 是数域 $F$ 上的线性空间，$T: V \to W$ 是线性映射，定义 $T$ 的加法和数乘如下：
> (1) $T_1 + T_2: V \to W, (T_1 + T_2)(x) = T_1(x) + T_2(x)$;
> (2) $\lambda T: V \to W, (\lambda T)(x) = \lambda T(x)$。
> 则 $T_1 + T_2$ 和 $\lambda T$ 仍然是 $V$ 到 $W$ 上的线性映射。

{注}: 线性空间$\mathcal{L}(V,W)$的维数为$\dim \mathcal{L}(V,W) = \dim V \cdot \dim W$。

##### *2.2.3 Theorem: 线性映射设空间*
> 集合$\mathcal{L}(V, W)$对定义2.2.2的加法和定义2.2.3的数乘构成数域$F$上的线性空间，称为线性映射空间。特别地，$\mathcal{L}(V)$称为线性变换空间。

##### *2.2.4 Theorem: 线性映射值空间和零空间*
> 设$T \in \mathcal{L}(V, W)$，定义
> $$\begin{array}{ll}
N(T) = \{x \in V \mid T(x) = \theta\}\\
R(T) = \{y \in W \mid y = T(x), \forall x \in V\}
\end{array}$$ 则$N(T)$是$V$的子空间，$R(T)$是$W$的子空间。我们称$N(T)$是线性映射$T$的核空间（或零空间），$R(T)$是线性映射$T$的像空间（或值空间）；并称$\operatorname{dim} N(T)$为线性映射$T$的零度（或亏），$\operatorname{dim} R(T)$为线性映射$T$的秩。


##### *2.2.5 Definition: 亏秩定理*
> 设 $T \in \mathcal{L}(V,W)$, 则 $\dim N(T) + \dim R(T) = \dim V$.

<details open>
  <summary>Proof:</summary> 

设线性空间 $V$ 的维数为 $n$，其子空间 $N(T)$ 的维数为 $m$。在 $N(T)$ 中取一组基 $\alpha_1,\cdots,\alpha_m$，并把它扩充为 $V$ 的基 $\alpha_1,\cdots,\alpha_m,\alpha_{m+1},\cdots,\alpha_n$，则对任意向量 $x\in V$ 有
\[ x=\sum_{i=1}^n k_i\alpha_i,\quad k_i\in F \] 从而
\[ T x=\sum_{i=1}^n k_i T\left(\alpha_i\right) \] 即
\[ R(T)=\operatorname{span}\left(T\left(\alpha_1\right),\cdots, T\left(\alpha_m\right), T\left(\alpha_{m+1}\right),\cdots, T\left(\alpha_n\right)\right) \] 注意到 $\alpha_1,\cdots,\alpha_m\in N(T)$，故 $T\left(\alpha_1\right)=\cdots=T\left(\alpha_m\right)=\theta$。由此，式可改写为
\[ R(T)=\operatorname{span}\left(T\left(\alpha_{m+1}\right),\cdots, T\left(\alpha_n\right)\right) \] 现只需证明 $T\left(\alpha_{m+1}\right),\cdots, T\left(\alpha_n\right)$ 线性无关，即可说明 $T\left(\alpha_{m+1}\right),\cdots, T\left(\alpha_n\right)$ 是 $R(T)$ 的一组基。
假设存在一组数 $l_i\in F, i=m+1,\cdots, n$，使得
\[ \sum_{i=m+1}^n l_i T\left(\alpha_i\right)=\theta \] 则根据线性映射定义知 \[ T\left(\sum_{i=m+1}^n l_i\alpha_i\right)=\theta \] 即 \[ \sum_{i=m+1}^n l_i\alpha_i\in N(T) \] 又知向量组 $\alpha_1,\cdots,\alpha_m$ 是 $N(T)$ 的一组基，故向量 $\sum_{i=m+1}^n l_i\alpha_i$ 一定可由向量组 $\alpha_1,\cdots,\alpha_m$ 线性表示，即
\[ \sum_{i=m+1}^n l_i\alpha_i=\sum_{i=1}^m l_i\alpha_i \] 整理得
$$\sum_{i=1}^{n} l_i \alpha_i = 0$$ 已知向量组 $\alpha_1,\cdots,\alpha_m,\alpha_{m+1},\cdots,\alpha_n$ 线性无关，故上式成立的充分必要条件为 $l_i=0, i=1,\cdots, n$。因此，我们推断出 $T\left(\alpha_{m+1}\right),\cdots, T\left(\alpha_n\right)$ 线性无关，即 $\text{dim } R(T) = n - m$。证毕。
</details>

##### *2.3.1 Definition: 矩阵*
> 设$T$是$V$到$W$上的线性映射, $\epsilon _1, \cdots, \epsilon _n$ 和 $\eta _1, \cdots, \eta _m$ 分别是 $V$ 和 $W$ 的基.
> 设$T(\epsilon  _1, \cdots, \epsilon  _n) = [T(\epsilon _1), \cdots , T(\epsilon _n)] = [\eta _1, \cdots, \eta _n  ]A$, $A \in F^{m \times n}$, 则称$A$是$T$在基$\epsilon _1, \cdots, \epsilon _n$和$\eta _1, \cdots, \eta _m$下的矩阵.

{注}: 
1. 基不一定为列向量,可以为矩阵或多项式
2. $A$与$T$一一对应(在基确定的情况下)
3. 当$V = W$时, $A$称为线性变换$T$的矩阵
4. 矩阵是线性映射在某组基下的表达(或坐标的线性变换)

##### *2.3.1 Theorem: <span id="them2.3.1">矩阵与线性映射关系</span>*
> 设$V$和$W$是数域$F$上的线性空间，取定$\varepsilon_1, \cdots, \varepsilon_n$和$\eta_1, \cdots, \eta_m$分别是$V$和$W$的一组基。任取$A = (a_{ij}) \in F^{m \times n}$，则有且仅有一个线性映射$T \in \mathcal{L}(V, W)$使其在$V$的基$\varepsilon_1, \cdots, \varepsilon_n$和$W$的基$\eta_1, \cdots, \eta_m$下的矩阵恰为$A$。

<details open>
  <summary>Proof:</summary> 

先证明存在性.
设 $\forall x, y \in V$, 其可表示为 $x = \sum_{j=1}^n \alpha_j \varepsilon_j, y = \sum_{j=1}^n \beta_j \varepsilon_j$, 则定义映射$T: V \rightarrow W$使得满足下列关系:
\[ T(x) = T(\sum_{j=1}^n \alpha_j \varepsilon_j)= \sum_{j=1}^{n} \sum_{i=1}^{m} \alpha_{j} a_{ij} \eta_{i} \] $\forall x, y \in 和 \lambda, \mu \in F W$ 有 \[ \begin{align*} T(\lambda x + \mu y) &= \sum_{j=1}^{n} \sum_{i=1}^{m} \left( \lambda \alpha_{j} + \mu \beta_{j} \right) a_{ij} \eta_{i} \\ &= \lambda \sum_{j=1}^{n} \sum_{i=1}^{m} \alpha_{j} a_{ij} \eta_{i} + \mu \sum_{j=1}^{n} \sum_{i=1}^{m} \beta_{j} a_{ij} \eta_{i} \\ &= \lambda T(x) + \mu T(y) \end{align*} \]
由映射 \( T \) 定义式知，\( \forall k = 1, \cdots, n \)，则 \[ T(\varepsilon_{k}) = \sum_{i=1}^{m} a_{ik} \eta_{i} = \left[\eta_{1}, \cdots, \eta_{m}\right] \left[\begin{array}{l} a_{1k} \\ \vdots \\ a_{mk} \end{array}\right] \] 则有\[ \left[T(\varepsilon_{1}), \cdots, T(\varepsilon_{n})\right] = \left[\eta_{1}, \cdots, \eta_{m}\right] A \]显然可以看出映射 \( T \) 在 \( V \) 的基 \( \varepsilon_1, \cdots, \varepsilon_n \) 和 \( W \) 的基 \( \eta_1, \cdots, \eta_m \) 下的矩阵为 \( A \).
下面证明唯一性.
假设存在另一个线性映射 \( \tilde{T} \)，且它在 \( V \) 的基 \( \varepsilon_1, \cdots, \varepsilon_n \) 和 \( W \) 的基 \( \eta_1, \cdots, \eta_m \) 下的矩阵也为 \( A \)。根据矩阵 \( A \) 的定义，有 \[ \begin{align*} &\tilde{T}(\varepsilon_k) = \left[\eta_1, \cdots, \eta_m\right] \left[\begin{array}{l} a_{1k} \\ \vdots \\ a_{mk} \end{array}\right] \quad \forall k = 1, \cdots, n \end{align*} \] 即 \( T(\varepsilon_k) = \tilde{T}(\varepsilon_k), k = 1, \cdots, n \)。因此，\( T = \tilde{T} \)，即线性映射 \( T \) 是唯一的。证毕。
</details>

{注}:
1. 给定一组基的情况下, 线性映射与矩阵一一对应
2. 类似于向量与坐标之间的关系
3. 在同一个变换下, 矩阵可以描述基变换

##### *2.3.\* Theorem: 线性映射和矩阵的关系*
> 定理2.3.1表明线性映射$T \in \mathcal{L}(V, W)$和$A = (a_{ij}) \in F^{m \times n}$存在着一一对应的关系，即存在着双射$f: \mathcal{L}(V, W) \rightarrow F^{m \times n}$满足$f(T) = A$。

##### *2.3.2 Definition: 同构*
> 设$V$和$W$是数域$F$上的线性空间，若存在双射$f: V \rightarrow W$满足
> $(1) f(x + y) = f(x) + f(y);$
> $(2) f(\lambda x) = \lambda f(x).$
> 其中：$x$和$y$是$V$中任意向量，$\lambda$是数域$F$的任意数，则称$f$是$V$到$W$的同构映射，并称线性空间$V$与$W$同构。

##### *2.3.2 Theorem: 线性映射和矩阵同构*
> 设$V$和$W$是数域$F$上的线性空间，它们的维数分别为$n$和$m$，则线性映射空间$\mathcal{L}(V, W)$和矩阵空间$F^{m \times n}$同构。

<details open>
  <summary>Proof:</summary> 

由 [定理2.3.1](#them2.3.1)可以看出线性映射 $T \in \mathcal{L}(V,W)$和矩阵$A \in F^{m \times n}$ 存在一一对应的关系, 即存在着双射 \( f: \mathcal{L}(V, W) \rightarrow F^{m \times n} \) 满足 \[ f(T) = A \] 实际上，映射 \( f \) 不仅是双射，还是线性映射，具体原因如下：
设 \( T_1, T_2 \in \mathcal{L}(V, W) \)，并令 \( T_1 \) 和 \( T_2 \) 在 \( V \) 的基 \( \varepsilon_1, \cdots, \varepsilon_n \) 和 \( W \) 的基 \( \eta_1, \cdots, \eta_m \) 下的矩阵分别为 \( A_1 \) 和 \( A_2 \)，则对任意 \( \lambda, \mu \in F \)，有 \( \lambda T_1 + \mu T_2 \) 是线性映射，且
\[ \begin{align*}
(\lambda T_1 + \mu T_2)(\varepsilon_1, \cdots, \varepsilon_n) &= [(\lambda T_1 + \mu T_2)(\varepsilon_1), \cdots, (\lambda T_1 + \mu T_2)(\varepsilon_n)] \\
&= [\lambda T_1(\varepsilon_1) + \mu T_2(\varepsilon_1), \cdots, \lambda T_1(\varepsilon_n) + \mu T_2(\varepsilon_n)] \\
&= \lambda [T_1(\varepsilon_1), \cdots, T_1(\varepsilon_n)] + \mu [T_2(\varepsilon_1), \cdots, T_2(\varepsilon_n)] \\
&= \lambda [\eta_1, \cdots, \eta_m] A_1 + \mu [\eta_1, \cdots, \eta_m] A_2 \\
&= [\eta_1, \cdots, \eta_m] (\lambda A_1 + \mu A_2)
\end{align*} \] 上式表明线性映射 \( \lambda T_1 + \mu T_2 \) 在 \( V \) 的基 \( \varepsilon_1, \cdots, \varepsilon_n \) 和 \( W \) 的基 \( \eta_1, \cdots, \eta_m \) 下的矩阵为 \( \lambda A_1 + \mu A_2 \)，即 \[ f(\lambda T_1 + \mu T_2) = \lambda A_1 + \mu A_2 \] 
</details>

*2.3 Proposition: 同构映射的性质* 
> 设 $V$ 和 $W$ 是数域 $F$ 上的线性空间，$T: V \to W$ 是同构映射，则有
> 1. $T(0) = 0', 0 \in V, 0' \in W$
> 2. $T(-x) = -T(x)$, 对于所有 $x \in V$
> 3. $T\left(\sum \alpha_i x_i\right) = \sum \alpha_i T(x_i)$, 对于所有 $\alpha_i \in F$ 和 $x_i \in V$
> 4. V中的向量组 $x_1, \cdots, x_r$ 线性相关，当且仅当其像 $T(x_1), \cdots, T(x_r)$ 线性相关
> 5. 若 $\varepsilon_1, \cdots, \varepsilon_n$ 是 V 的一组基，则 $T(\varepsilon_1), \cdots, T(\varepsilon_n)$ 是 W 的一组基
> 6. T的逆映射 $T^{-1}: W \rightarrow V$ 存在且是同构映射

<details open>
  <summary>Proof:</summary> 

1~4显然, 下面证5.
由[定理2.2.2](#them2.2.2)知，若 \( \varepsilon_1, \cdots, \varepsilon_n \) 是 \( V \) 的一组基，则向量组 \( T(\varepsilon_1), \cdots, T(\varepsilon_n) \) 必线性无关。又知对任意向量 \( y \in W \)，必存在 \( x \in V \) 使得 \( T(x) = y \)，其中 \( x \) 可由基 \( \varepsilon_1, \cdots, \varepsilon_n \) 线性表示为 \( x = \sum_{j=1}^n \alpha_j \varepsilon_j \)。由此\[ y = T\left(\sum_{j=1}^n \alpha_j \varepsilon_j\right) = \sum_{j=1}^n \alpha_j T(\varepsilon_j) \] 即 \( W \) 中任意向量 \( y \) 总可由向量组 \( T(\varepsilon_1), \cdots, T(\varepsilon_n) \) 线性表示。于是， \( T(\varepsilon_1), \cdots, T(\varepsilon_n) \) 是 \( W \) 的一组基。这同时表明线性空间 \( W \) 的维数与线性空间 \( V \) 的维数相同。
</details>

##### *2.3.3 Theorem: 线性空间同构*
>  线性空间同构当仅当它们的维数相等。

<details open>
  <summary>Proof:</summary> 

必要性是显然的. 下面证明充分性. 即对于维数相等的空间存在同构映射(即满足线性映射的双射).
设 \( V \) 和 \( W \) 均是数域 \( F \) 上的 \( n \) 维线性空间，向量组 \( \varepsilon_1, \cdots, \varepsilon_n \) 和 \( \eta_1, \cdots, \eta_n \) 分别是 \( V \) 和 \( W \) 的一组基。
定义映射 \( T: V \rightarrow W \) 满足
\[ T(x) = \sum_{i=1}^n \alpha_i \eta_i, \quad \forall x \in V \] 式中：\( \alpha = [\alpha_1, \cdots, \alpha_n]^T \) 是向量 \( x \) 在基 \( \varepsilon_1, \cdots, \varepsilon_n \) 下的坐标。
由此，对任意向量 \( x, y \in V \) 和 \( \lambda, \mu \in F \)，有
\[ T(\lambda x + \mu y) = \sum_{i=1}^n (\lambda \alpha_i + \mu \beta_i) \eta_i = \lambda T(x) + \mu T(y) \] 式中：\( \beta = [\beta_1, \cdots, \beta_n]^T \) 是向量 \( y \) 在基 \( \varepsilon_1, \cdots, \varepsilon_n \) 下的坐标。上式表明 \( T \) 是线性映射。若 \( T(x) = T(y) \)，即
\[ T(x) - T(y) = \sum_{i=1}^n (\alpha_i - \beta_i) \eta_i = \theta \] 则有 \( \alpha = \beta \)，即 \( x = y \)。于是当 \( x \neq y \) 时，\( T(x) \neq T(y) \)，这表明线性映射 \( T \) 是单射。
对任意向量 \( z \in W \) 有\[ z = \sum_{i=1}^n \gamma_i \eta_i \] 式中：\( \gamma = [\gamma_1, \cdots, \gamma_n]^T \) 是向量 \( z \) 在基 \( \eta_1, \cdots, \eta_n \) 下的坐标。
定义
\[ \tilde{x} = \sum_{j=1}^n \gamma_j \varepsilon_j \] 则有 \( \tilde{x} \in V \)，且 \( T(\tilde{x}) = z \)。这表明线性映射 \( T \) 是满射。综上所述，映射 \( T \) 是同构映射，即线性空间 \( V \) 和 \( W \) 是同构的。
</details>

##### *2.3.1 Corollary* 
> 任一实(复) n维线性空间均与 $\mathbb{R}^n(\mathbb{C}^n)$ 同构。

##### *2.3.2 Corollary*
> 设 $V$ 和 $W$ 是数域 $F$ 上的线性空间, 它们维数分别为 $n$ 和 $m$, 则 $\operatorname{dim}(L(V, W))=\operatorname{dim}(F^m \times F^n)=mn$。

##### *2.3.3 Corollary* 
> 设 $V$ 是数域 $\mathbb{R}$ (或 $\mathbb{C}$) 上的 n维线性空间, 则线性变换空间 $L(V)$ 与 $\mathbb{R}^{n^2}$ (或 $\mathbb{C}^{n^2}$) 同构。

##### *2.3.4 Theorem: 坐标变换*
> 设$V$和$W$是数域$F$上的线性空间，$T: V \to W$是线性映射，$\epsilon _1, \cdots, \epsilon _n$和$\eta _1, \cdots, \eta _m$分别是$V$和$W$的基，$A$是$T$在这两组基下的矩阵，$x \in V$的坐标为$\alpha$，$T(x)$在基$\eta _1, \cdots, \eta _m$下的坐标为$\beta$，则有$\beta = A\alpha$.

<details open>
  <summary>Proof:</summary> 

必要性由命题 2.3.1性质(5)证得。这里只证明充分性。设 \( V \) 和 \( W \) 均是数域 \( F \) 上的 \( n \) 维线性空间，向量组 \( \varepsilon_1, \cdots, \varepsilon_n \) 和 \( \eta_1, \cdots, \eta_n \) 分别是 \( V \) 和 \( W \) 的一组基。定义映射 \( T: V \rightarrow W \) 满足
\[ T(x) = \sum_{i=1}^n \alpha_i \eta_i, \quad \forall x \in V \] 式中：\( \alpha = [\alpha_1, \cdots, \alpha_n]^T \) 是向量 \( x \) 在基 \( \varepsilon_1, \cdots, \varepsilon_n \) 下的坐标。
由此，对任意向量 \( x, y \in V \) 和 \( \lambda, \mu \in F \)，有
\[ T(\lambda x + \mu y) = \sum_{i=1}^n (\lambda \alpha_i + \mu \beta_i) \eta_i = \lambda T(x) + \mu T(y) \] 式中：\( \beta = [\beta_1, \cdots, \beta_n]^T \) 是向量 \( y \) 在基 \( \varepsilon_1, \cdots, \varepsilon_n \) 下的坐标。上式表明 \( T \) 是线性映射。若 \( T(x) = T(y) \)，即
$$ T(x) - T(y) = \sum_{i=1}^n (\alpha_i - \beta_i) \eta_i = \theta $$ 则有 \( \alpha = \beta \)，即 \( x = y \)。于是当 \( x \neq y \) 时，\( T(x) \neq T(y) \)，这表明线性映射 \( T \) 是单射。
对任意向量 \( z \in W \) 有 \[ z = \sum_{i=1}^n \gamma_i \eta_i \] 式中：\( \gamma = [\gamma_1, \cdots, \gamma_n]^{\top} \) 是向量 \( z \) 在基 \( \eta_1, \cdots, \eta_n \) 下的坐标。
定义 \[ \tilde{x} = \sum_{j=1}^n \gamma_j \varepsilon_j \] 则有 \( \tilde{x} \in V \)，且 \( T(\tilde{x}) = z \)。这表明线性映射 \( T \) 是满射。
综上所述，映射 \( T \) 是同构映射，即线性空间 \( V \) 和 \( W \) 是同构的。证毕。
</details>

下面这张图很好的解释了线性映射与矩阵的关系:
<p align="center"><img src="./assert/图2-3-1.png" width="600" > </img></p>

{注}: 
1. 矩阵作用在向量坐标上等效于线性映射作用在原向量上.
2. 在此可以抽象的把所有线性映射看作矩阵的乘法, 我们可以人为的规定不同的基, 从而全部规约到矩阵与向量的乘法, 所以在此之后只讨论矩阵与向量的乘法.
3. 对于线性映射空间的一切性质都转换为对矩阵的研究.
4. $m \times n$阶矩阵与n维向量的乘法操作代表了某个n维线性空间中的向量正在经历线性变换。任何n维线性空间内的线性运算都可以等价为在$\mathbb{R}^n$（或$\mathbb{C}^n$）空间中的向量线性运算，因为n维线性空间与$\mathbb{R}^n$或$\mathbb{C}^n$是同构的。两个线性空间之间定义的线性映射可以等价为在$\mathbb{R}^{n \times n}$（或$\mathbb{C}^{n \times n}$）中的矩阵与$\mathbb{R}^n$（或$\mathbb{C}^n$）空间的向量进行乘法运算，即线性映射空间与其对应的矩阵空间是同构的。基于上述等价关系，我们可以将同构线性空间视为同一个线性空间。

##### *2.3.5 Theorem: 基变换对线性映射对应矩阵的影响*
> 设$V$和$W$是数域$F$上的$n$维和$m$维线性空间，$\alpha_1, \alpha_2, \ldots, \alpha_n$和$\beta_1, \beta_2, \ldots, \beta_m$是$V$的两组基，由$\alpha_1, \alpha_2, \ldots, \alpha_n$到$\beta_1, \beta_2, \ldots, \beta_m$的过渡矩阵为$Q$；$\gamma_1, \gamma_2, \ldots, \gamma_m$和$\delta_1, \delta_2, \ldots, \delta_m$是$W$的两组基，由$\gamma_1, \gamma_2, \ldots, \gamma_m$到$\delta_1, \delta_2, \ldots, \delta_m$的过渡矩阵为$P$；设线性映射$T \in L(V, W)$在$V$的基$\alpha_1, \alpha_2, \ldots, \alpha_n$和$W$的基$\gamma_1, \gamma_2, \ldots, \gamma_m$下的矩阵为$A$，$T$在$V$的基$\beta_1, \beta_2, \ldots, \beta_n$和$W$的基$\delta_1, \delta_2, \ldots, \delta_m$下的矩阵为$B$，则$B = P^{-1}APQ$

##### *2.3.4 Corollary: 基变换对线性变换对应矩阵的影响*
> 设$V$是数域$F$上的$n$维线性空间，$\varepsilon_1, \cdots, \varepsilon_n$和$\varepsilon_1', \cdots, \varepsilon_n'$是$V$的两组基，由$\varepsilon_1, \cdots, \varepsilon_n$到$\varepsilon_1', \cdots, \varepsilon_n'$的过渡矩阵为$P$，线性变换$T \in \mathcal{L}(V)$在基$\varepsilon_1, \cdots, \varepsilon_n$和基$\varepsilon_1', \cdots, \varepsilon_n'$下的矩阵分别为$A$和$B$，则$B = P^{-1}AP$

##### *2.3.6 Theorem: 线性映射的维数性质*
> 设$V$和$W$是数域$F$上的$n$维和$m$维线性空间，若$T \in \mathcal{L}(V, W)$在$V$的基$\varepsilon_1, \cdots, \varepsilon_n$和$W$的基$\eta_1, \cdots, \eta_m$下的矩阵为$A$，则:
>(1) $\operatorname{dim} N(T) = \operatorname{dim} N(A)$
>(2) $\operatorname{dim} R(T) = \operatorname{dim} R(A) = \operatorname{rank}(A)$;
>(3) $\operatorname{dim} N(A) + \operatorname{dim} R(A) = n$（秩-零度定理）

##### *2.3.6 Example*
>  考察齐次线性差分方程
\[ u_{k+n} + a_{n-1} u_{k+n-1} + \cdots + a_1 u_{k+1} + a_0 u_k = 0 \] \( k = 0, \pm 1, \pm 2, \cdots \)。方程的解集 \( \widetilde{S} \) 是 \( S \) 的一个线性子空间。若定义
\[ x_k = \left[\begin{array}{c} u_k \\ u_{k+1} \\ \vdots \\ u_{k+n-1} \end{array}\right] \in \mathbb{R}^n, \quad A = \left[\begin{array}{ccccc} 0 & 1 & 0 & \cdots & 0 \\ 0 & 0 & 1 & \cdots & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & 0 & \cdots & 1\\ -a_0 & -a_1 & a_2 &...& -a_{n-1}\end{array}\right] \in \mathbb{R}^{n \times n} \] 则上式可改写为
\[ x_{k+1} = A x_k, \quad k = 0, \pm 1, \pm 2, \cdots \] 由该式易验证，当 \( x_0 \) 给定，序列 \( \{ u_k \} \) 唯一确定。因此，定义映射 \( T: \widetilde{S} \rightarrow \mathbb{R}^n \) 满足
\[ T\left( \left\{ u_k \right\} \right) = x_0 \] 易证 \( T \) 是同构映射。因此，\( \operatorname{dim}(\widetilde{S}) = \operatorname{dim}(\mathbb{R}^n) = n \)，即 \( \widetilde{S} \) 是 \( S \) 的一个 \( n \) 维线性子空间.

##### *2.4.1 Theorem: 线性变换特征值特征向量*
> 设线性变换$T \in L(V)$,若存在 $\lambda_{0} \in F$ 及$V$的非零向量$\xi$ 使得 $T(\xi) = \lambda_0 \xi$, 则称 $\lambda_0$ 是 $T$的一个特征值,称 $\xi$ 为 $T$的属于特征值 $\lambda_0$ 的一个特征向量

<details open>
  <summary>Proof:</summary>


</details>

{注}: 特征向量一定为非零向量, 特征值可以为0.

##### *2.4.1 Example: 特征向量空间*
> $T$的特征值$\lambda$的所有特征向量组成的集合是线性空间吗?
> 显然不是, 因为零向量不是特征向量.

{注}: 设$T \in L(V)$，$\{v_1, v_2, \ldots, v_n\}$是$V$的一组基，且$T(v_i) = \lambda_i v_i$（$i = 1, 2, \ldots, n$），则$T$在基$\{v_1, v_2, \ldots, v_n\}$下的矩阵为对角阵。

##### *2.4.2 Definition: 矩阵的特征值和特征向量*
> 设 $A\in F^{n\times n},\lambda$ 为一标量，矩阵 $\lambda I-A$ 称为$A$的特征矩阵，其行列式 $|\lambda I-A|$ 称为$A$的特征多项式，方程 $|\lambda I-A|=0$ 的根称为$A$的特征值（或特征根）。方程 $(\lambda I-A)\alpha=0$ 的非零解向量$\alpha$称为属于特征值 $\lambda$ 的特征向量。

{注}: 
$\lambda $ 不一定为实数.

##### *2.4.\* Theorem: 线性变换特征值和矩阵特征值关系*
> $\lambda$是线性变换$T$的特征值当且仅当$\lambda$是$A$的特征值; 向量$\alpha$是线性变换$T$的特征向量当且仅当$\alpha$是$A$的特征向量，其中$A$是$T$在线性空间$V$的基$\{v_1, v_2, \ldots, v_n\}$下的矩阵表示, $\alpha$和$\beta$分别是向量$\alpha$在基$\{v_1, v_2, \ldots, v_n\}$下的坐标向量.

<details open>
  <summary>Proof:</summary>

> 设 $T(x) =\lambda x$, $\epsilon _1, \cdots, \epsilon _n $为 $V$ 的一组基, $x = \sum_{i=1}^n \alpha_i \epsilon _i$, 则有 $T(x) = \sum_{i=1}^n \alpha_i T(\epsilon _i) = (T(\epsilon_1), \cdots, T(\epsilon _n)) \cdot (\alpha _1, \cdots , \alpha _n)^\top = ( \epsilon _1, \cdots , \epsilon _n )A(\alpha _1, \cdots , \alpha _n)^\top = \lambda x = (\epsilon _1, \cdots, \epsilon _n)\lambda (\alpha _1, \cdots, \alpha _n)^\top $, 即 $\lambda \alpha  = A \alpha$, 其中 $A$ 是 $T$ 在基 $\epsilon _1, \cdots, \epsilon _n$ 下的矩阵表示, $\alpha$ 是 $x$ 在基 $\epsilon _1, \cdots, \epsilon _n$ 下的坐标向量. 证毕.
</details>

{注}:矩阵 $A \in F^{n \times n}$不一定有$n$个特征值, 依赖于 $V$所在的数域 $F$.

##### *2.4.1 Theorem: 矩阵的迹与特征值*
> 设 $\lambda_1,\cdots,\lambda_n$ 是矩阵 $A=\left(a_{i j}\right)\in C^{n\times n}$ 的特征值，则有：
> $$
> \prod_{i=1}^n\lambda_i=|A|, 
> \sum_{i=1}^n\lambda_i=\sum_{i=1}^n a_{i i}=\operatorname{tr}(A)
> $$

###### Lemma: 维达定理
设 $P(x)=a_{n} x^{n}+a_{n-1} x^{n-1}+\cdots+a_{1} x+a_{0}$ 是一个一元 n 次实（或复）系数多项式，首项系数 $a_{n}\neq 0$，令 P 的 n 个根为 $x_{1}, x_{2},\ldots, x_{n}$，则根 $\left\{x_{i}\right\}$ 和系数 $\left\{a_{j}\right\}$ 之间满足关系式：
$$
\left\{
\begin{array}{l}
x_{1}+x_{2}+\cdots+x_{n}=-\frac{a_{n-1}}{a_{n}} \\
\left(x_{1} x_{2}+x_{1} x_{3}+\cdots+x_{1} x_{n}\right)+\left(x_{2} x_{3}+x_{2} x_{4}+\cdots+x_{2} x_{n}\right)+\cdots+x_{n-1} x_{n}=\frac{a_{n-2}}{a_{n}} \\
\quad\vdots \\
x_{1} x_{2}\ldots x_{n}=(-1)^{n}\frac{a_{0}}{a_{n}}
\end{array}
\right.
$$

<details open>
  <summary>Proof:</summary> 

由代数基本定理有, $f(\lambda ) = |\lambda I-A| = \prod_{i=1}^{n}\left(\lambda-\lambda_{i}\right)=a_{n}\lambda^{n}+a_{n-1}\lambda^{n-1}+\cdots+a_{1}\lambda+a_{0}$
显然只有 $|\lambda I-A|$的对角线才能产生 $\lambda^n$ 和 $\lambda ^{n-1}$的项. 关注特征多项式对角线, 即 $(\lambda -a_{11})\cdots (\lambda -a_{nn})$, 显然 $ \lambda ^n$ 的系数为1, $\lambda ^{n-1}$ 的系数为 $-(a_{11} + \cdots + a_{nn})$, 所以 $\sum_{i=1}^n\lambda_i=\sum_{i=1}^n a_{i i}=\operatorname{tr}(A)$.
显然知 $f(\lambda )$ 的常数项为 $a_0 = f(0) = (-1)^n |A|$, 所以 $\prod_{i=1}^n\lambda_i=|A|$.
</details>

##### *2.4.4 Example: 特征值的性质*
> 设 $\lambda$ 是可逆复方阵 $A$ 的特征值, 试证明:
> (1)$\lambda^{-1}$ 是 $A^{-1}$ 的特征值;
> (2)$\lambda^{-1}A^{-1}$ 是 $A^*$ 的特征值.

<details open>
  <summary>Proof:</summary>

(1) 当 $A$ 可逆时，$\lambda \neq 0$。令 $x$ 是属于特征值 $\lambda$ 的特征向量，则有：
$$
Ax = \lambda x
$$

对上式左右两端乘以 $A^{-1}$，并整理得：
$$
A^{-1}x = \lambda^{-1}x
$$

故 $\lambda^{-1}$ 是 $A^{-1}$ 的特征值。
(2) 根据 $AA^* = AI$ 知，$A^* \lambda AA^{-1} = \lambda I$，故 $\lambda^{-1}A^{-1}$ 是 $A^*$ 的特征值。
</details>

##### *2.4.4 Supplement: 伴随矩阵*
> 设 $A \in F^{n \times n}$, 称矩阵 $A^* = \left( A_{i j} \right) \in F^{n \times n}$ 为 $A$ 的伴随矩阵, 其中 $A_{i j}$ 是 $A$ 的代数余子式, 即 $A_{i j} = (-1)^{i+j} M_{i j}$, 其中 $M_{i j}$ 是 $A$ 的子式, $M_{i j}$ 是 $A$ 去掉第 $i$ 行和第 $j$ 列后得到的 $n-1$ 阶子式的行列式.

性质:
1. $A A^* = A^* A = |A|I$
2. $\operatorname{rank}\left(A^{*}\right)=\left\{\begin{array}{l}n,\operatorname{rank}(A)=n\\ 1,\operatorname{rank}(A)=n-1\\ 0,\operatorname{rank}(A)\leq n-2\end{array}\right.$

<details open>
  <summary>Proof:</summary> 

当 $\operatorname{rank}(A) = n$ 时, $A^* = |A|A^{-1}$, 显然 $\operatorname{rank}(A^*) = n$.
当 $\operatorname{rank}(A) = n-1$ 时, 其只有 $n-1$ 个线性无关的列, 不妨设为前 $n-1$ 列, 显然只有 $A_{in} \neq 0$, 所以 $\operatorname{rank}(A^*) = 1$.
当 $\operatorname{rank}(A) \leq n-2$ 时, 显然有 $A_{ij} = 0$, 所以 $\operatorname{rank}(A^*) = 0$.
</details>

##### *2.4.3 Definition: 特征子空间*
> 设 \(\lambda\) 是矩阵 \(A \in \mathbb{C}^{n \times n}\) 的一个特征值, 定义集合 \(E_{\lambda} = \{x \in \mathbb{C}^n | Ax = \lambda x\}\)。则 \(E_{\lambda}\) 是 \(\mathbb{C}^n\) 的线性子空间, 称为属于特征值 \(\lambda\) 的特征子空间, \(\dim(E_{\lambda})\) 为特征值 \(\lambda\) 的几何重数.

{注}: 
1. $E(\lambda )$ 中需要包括零向量.
2. $\dim(E(\lambda )) = n - \operatorname{rank}(A-\lambda I)    $
3. 一元 $n$次多项式在复数域内一定有 $n$ 个根, 其中$\lambda _i $ 为特征方程的重数, 称为代数重数.

##### *2.4.2 Theorem: 特征值几何重数定理*
> 复方阵的任一特征值的几何重数不超过它的代数重数.

<details open>
  <summary>Proof:</summary> 

设 $\lambda_0$ 为 $n$ 阶矩阵 $A \in \mathbb{C}^{n \times n}$ 的一个特征值，其代数重数和几何重数分别为 $m$ 和 $k$。由此，设 $p_1, \cdots, p_k$ 是特征子空间 $E(\lambda_0)$ 的一组基。由基扩充定理知，可将它扩充为 $\mathbb{C}^n$ 的一组基，记为 $p_1, \cdots, p_k, p_{k+1}, \cdots, p_n$。
定义 $P=\left[p_1,\cdots, p_k, p_{k+1},\cdots, p_n\right]\in \mathbb{C}^{n\times n}$
$$ P^{-1} A P=\left[\begin{array}{ll}\Lambda_0& B_1\\ 0& B_2\end{array}\right]\stackrel{\text{def}}{=} B$$ 式中：$\Lambda_0$ 为以 $\lambda_0$ 为对角元素的 $k$ 阶矩阵，$B_2$ 为 $(n-k)$ 阶矩阵。
由于 $A$ 与 $B$ 相似，故它们有相同的特征值。注意到 $B$ 的特征多项式为
$$\left|\lambda I_n-B\right|=\left(\lambda-\lambda_0\right)^k\left|\lambda I_{n-k}-B_2\right|$$ 即 $\lambda_0$ 在 $B$ 中的代数重数至少为 $k$，故它在 $A$ 中的代数重数也至少为 $k$，于是有 $m\geqslant k$。证毕。
</details>

##### *2.4.1 Proposition: 相似矩阵的性质*
> 若\(n\)阶方阵\(A\)与\(B\)相似, 即存在可逆矩阵 $P$, 使得$ P^{-1}BP=A$ 则：
> (1) \(A\)与\(B\)有相同的特征多项式与特征值；
> (2) \(A\)与\(B\)有相同的秩与行列式；
> (3) \(A\)与\(B\)有相同的迹。

<details open>
  <summary>Proof:</summary> 

(1) $由 Ax = \lambda x, 得 P^{-1}BPx = \lambda x$, 即 $B(Px) = \lambda (Px)$, 显然特征值相同, 则特征多项式也相同.
(2) 可逆矩阵都可以表示为初等矩阵的乘积, 初等矩阵不改变矩阵的秩, 所以 $A, B$ 秩相同.
(3) 显然迹为特征值之和, 所以迹相同.
</details>

{注}: 
1. 线性变换的矩阵的特征多项式与基的选取无关，它直接由线性变换决定，故可称之为线性变换的特征多项式.
2. 显然相似矩阵的特征向量可以不同.

##### *2.4.3 Theorem: 特征向量的线性无关性*
> 矩阵\(A\)的属于不同特征值的特征向量线性无关。

<details open>
  <summary>Proof:</summary> 

设\(\lambda_1, \cdots, \lambda_r\)是\(n\)阶矩阵\(A\)的\(r\)个互不相同的特征值，\(\alpha_1, \cdots, \alpha_r\)是分别属于特征值\(\lambda_1, \cdots, \lambda_r\)的特征向量。
考察向量方程
\[
k_1\alpha_1 + \cdots + k_r\alpha_r = 0 \qquad (2.4.3)
\] 式中\(k_1, \cdots, k_r \in F\)为待定系数。
对式(2.4.3)两端左乘矩阵\(A, A^2, \cdots, A^{n-1}\)，得如下方程组：
\[
\begin{gathered}
k_1\lambda_1\alpha_1 + \cdots + k_r\lambda_r\alpha_r = 0 \\
k_1\lambda_1^2\alpha_1 + \cdots + k_r\lambda_r^2\alpha_r = 0 \\
\vdots \\
k_1\lambda_1^{n-1}\alpha_1 + \cdots + k_r\lambda_r^{n-1}\alpha_r = 0
\end{gathered}
\] 联合式(2.4.3)，有
\[
\left[k_1\alpha_1, \cdots, k_r\alpha_r\right] D^{\top} = 0 \qquad (2.4.4)
\] 其中
\[
D = \left[\begin{array}{cccc}
1 & 1 & \cdots & 1 \\
\lambda_1 & \lambda_2 & \cdots & \lambda_r \\
\vdots & \vdots & & \vdots \\
\lambda_1^{n-1} & \lambda_2^{n-1} & \cdots & \lambda_r^{n-1}
\end{array}\right]
\] 由于\(|D| = \prod_{i < j} (\lambda_i - \lambda_j)\)，知\(D\)为可逆矩阵。对式(2.4.4)两端右乘矩阵\((D^\top )^{-1}\)，得
\[
\left[k_1\alpha_1, \cdots, k_r\alpha_r\right] = 0
\] 由于\(\alpha_1, \cdots, \alpha_r \neq 0\)，故\(k_1 = k_2 = \cdots = k_r = 0\)。因此，矩阵\(A\)的属于不同特征值的特征向量线性无关。
</details>

##### *2.5.1 Definition: 正交变换和酉变换*
> 若欧氏（酉）空间中的线性变换\(T\)保持向量的内积不变，即对\(V\)的任意向量\(x\)与\(y\)有
> \[
> (T(x), T(y)) = (x, y)
> \] 则称\(T\)为正交（酉）变换。

##### *2.5.2 Definition: 正交矩阵和酉矩阵*
> 若\(n\)阶实方阵\(A\)满足\(A^T A = I\)或\(A A^T = I\)，则称\(A\)为正交矩阵；若\(n\)阶复方阵\(A\)满足\(A^H A = I\)或\(A A^H = I\)，则称\(A\)为酉矩阵。

##### *2.5.1 Theorem: 正交(酉)变换的性质*
> 设\(V\)是\(n\)维欧氏（酉）空间，\(T \in L(V)\)，则以下命题等价：
> (1) \(T\)是正交（酉）变换；
> (2) \(T\)保持长度不变，即\(\|T(x)\| = \|x\|\)；
> (3) 若\(\xi_1, \cdots, \xi_n\)是\(V\)中一组标准正交基，则\(T(\xi_1), \cdots, T(\xi_n)\)也是\(V\)中一组标准正交基；
> (4) \(T\)在\(V\)的任一标准正交基下的矩阵\(A\)为正交（酉）矩阵。

{注}: 正交矩阵 $A$ 的特征值不一定为$\pm1$, 有可能是复数.
<details open>
  <summary>Proof:</summary> 

设 $\lambda$ 是 $A$ 的任一特征值，$x$ 是属于 $\lambda$ 的特征向量, 则有 $Ax = \lambda x $, 两端取转置, 得 $x^H A^H = \bar{\lambda}x^H$,等式两端分别相乘得 $ x^H A^H A x = \bar{\lambda} \lambda x^H x$ 由 $A^H A = I$ 得， $x^H x = \bar{\lambda } x^H x $, 则 $ \|\lambda\|^2 = 1 $
</details>

##### *2.5.1 Proposition: 正交（酉）矩阵性质*
> (1) 正交矩阵的行列式必为 $\pm 1$，酉矩阵的行列式的模值为 $1$。
> (2) $A^{-1} = A^H$ 均为正交（酉）矩阵。
> (3) 正交（酉）矩阵的乘积仍为正交（酉）矩阵。
> (4) $A$ 的所有特征值的模值为 $1$。

<details open>
  <summary>Proof:</summary> 

(1) $|AA^H| = |A||A^H| = |A|^2 = 1$
(2) 显然成立.
(3) 设有酉矩阵 $B$, 则 $(AB)^H(AB) = (B^HA^H)(AB) = B^H(A^HA)B = I$.
(4) 证明见上.
</details>

##### *2.5.2 Theorem: 正交（酉）矩阵条件*
> 矩阵\(A\)是\(n\)阶正交（酉）矩阵当且仅当矩阵\(A\)的\(n\)个列（行）向量构成\(n\)维欧氏（酉）空间的一组标准正交基。

##### *2.5.2 Proposition: Givens矩阵的性质*
\[(t_{kl}(i, j))_{n \times n} = \begin{array}{ccccc}
\cos\varphi & 0 & \cdots & 0 & \sin\varphi \\
 & 1 & 0 && 0 \\
\vdots && \ddots && \vdots \\
0 &&& 1 & 0 \\
-\sin\varphi & 0 & \cdots & 0 & \cos\varphi \\
\end{array}\]

其中：\( t_{ii}(i, j) = t_{jj}(i, j) = \cos\varphi, \) \( t_{ij}(i, j) = \sin\varphi, \), \( t_{ji}(i, j) = -\sin\varphi \). 对于 \( k \neq i, j \), \( t_{kk}(i, j) = 1 \)，并且对于任意 \( k \neq i, j \) 和 \( l \neq i, j \), \( t_{kl}(i, j) = 0 \)。 矩阵 \( T(i, j) \) 被称为Givens矩阵(或初等旋转矩阵)。
> 设Givens矩阵\(T(i, j) \in \mathbb{R}^{n \times n}\)，则以下命题成立：
> (1) \(T(i, j)\)是正交矩阵且\((T(i, j))^{-1} = (T(i, j))^{\top}\). 
> (2) 设\(x = \left[x_1, \cdots, x_n\right]^{\top}\)，若\(y = T(i, j)x = \left[y_1, \cdots, y_n\right]^{\top}\)，则
> \[
> y_k = x_k, \quad k \neq i, j
> \]\[
> y_i = \cos\varphi x_i + \sin\varphi x_j
> \]\[
> y_j = -\sin\varphi x_i + \cos\varphi x_j
> \]

<details open>
  <summary>Proof:</summary> 

(1) 由 $t_{kl}(i, j)^\top t_{kl}(i, j) = I$ 可知.
(2) 显然成立.
</details>

{注}: 若 $\sqrt[]{x_i^2+x_j^2 }\neq 0$, 可定义
\[\cos\varphi = \frac{x_i}{\sqrt{x_i^2 + x_j^2}}, \quad \sin\varphi = \frac{x_j}{\sqrt{x_i^2 + x_j^2}}\]

则有 $y_i=\sqrt[]{x_i^2 + x_j^2}, y_j = 0$, 显然可以经过有限次Givens变换 $T$使得 $Tx=\|x\|e_1$.


##### *2.5.3 Definition: Householder矩阵*
> 设\(w \in \mathbb{C}^n\)是单位向量，定义矩阵\[H(w) = I - 2ww^H\]称为Householder矩阵（或初等反射矩阵）。

{注}: 
对于二维平面, 设 $w$ 为单位向量, 如下图所示.
有 $x+2p = y$, $x + p = Proj_{W^\perp }x = x - (x,w)w$
则有 $y = x - 2ww^Hx = H(x)w$

<p align="center"><img src="./assert/图2-5-1.png" width="600" > </img></p>

##### *2.5.3 Proposition: Householder矩阵的性质*
> Householder矩阵\(H(w)\)具有以下性质：
> \((1) |H(w)| = -1\).
> (2) \((H(w))^H = H(w) = (H(w))^{-1}\)；
> (3) 设 \( x, y \in \mathbb{C}^n \) 且 \( x \neq y \)，则存在单位向量 \( w \) 使得 \( H(w)x = y \) 的充分必要条件是： \[ x^H x = y^H y, \quad x^H y = y^H x \] 并且若上述条件成立，则使 \( H(w)x = y \) 成立的单位向量 \( w \) 可取为： \[ w = \frac{e^{i\theta}}{\|x-y\|}(x-y) \] 其中 \( \theta \) 为任一实数。

<details open>
  <summary>Proof:</summary> 

(1) 显然 $H(w)w = (I-2ww^H)w = w - 2ww^Hw = -w$, 则 $\lambda = -1$ 为一个特征值, $w$ 为一个特征向量.
$\forall y \in W ^\perp $, $H(w)y = (I-2ww^H)y = y - 2ww^Hy = y$, 显然 $\lambda = 1$ 为一个特征值, $y$ 为特征向量. 由于几何重数一定小于等于代数重数, 所以 $\lambda = \pm 1$为所有的特征值, 所以 $|H(w)| = -1$.
(2) $(H(w))^H = (I-2ww^H)^H = I - 2ww^H = H(w)$
$H(w)(H(w))^H = H(w)H(w) = (I - 2ww^H)(I - 2ww^H) = I - 2ww^H - 2ww^H + 4ww^Hww^H = I$. $(H(w))^H = (H(w))^{-1}$
(3) 
必要性.
巧用 $w^H w = 1$
$y^H y = (x^H - 2x^Hww^H)(x - 2ww^Hx) = x^Hx - 2x^Hww^Hx - 2x^Hww^Hx + 4x^Hww^Hx = x^Hx$
$\begin{aligned}
x^Hy &= x^H(I - 2ww^H)x \\
&= x^Hx - 2x^Hww^Hx \\
&= y^Hy - 2x^Hww^Hx \\
&= y^H(I - 2ww^H)x - 2x^Hww^Hx \\
&= y^Hx - 2y^Hww^Hx - 2x^Hww^Hx \\
&= y^Hx - 2x^H (I-2ww^H)ww^Hx - 2x^Hww^Hx \\
&= y^Hx - 2x^Hww^Hx + 4x^Hww^Hww^Hx - 2x^Hww^Hx \\ 
&= y^Hx
\end{aligned}$
充分性.
已知 $x^Hx = y^Hy, x^Hy = y^Hx$.
显然 $w = \frac{e^{i\theta}}{\|x-y\|}(x-y)$ 和 $ w^\perp  = \frac{e^{i\theta}}{\|x+y\|}(x+y)$ 正交.
则取 $p = \frac{1}{2}(y - x)$, $x + p = \frac{1}{2} (y + x)$, 则可验证 $x, p, x + p$ 构成直角三角形. 显然, $p = -Proj_{w}x$
则 $y = x + 2p = x - 2w(x,w) = x - 2 ww^Hx = I(w)x$. 证毕.
</details>

##### *2.5.3 Example*
> 给定实方阵 $A$, 是否存在有限个Givens矩阵或Householder矩阵的乘积, 记为 $T$, 使得 $TA$ 变成如下形式：
> $$ U = \left[\begin{array}{cccc}
\lambda_1 & * & \cdots & * \\
0 & \lambda_2 & \cdots & \vdots \\
\vdots & \cdots & \ddots & * \\
0 & \cdots & 0 & \lambda_n
\end{array}\right]$$
> 其中, *为任意实数，$\lambda_1, \cdots, \lambda_n$是$n$个实数.

<details open>
  <summary>Proof:</summary>

对于 $ T(i,j)A = T(i,j)\left[a_1, \cdots ,a_n\right]$ 可以选取 $T(i,j)$ 使得 $a_i$ 的第 $i$ 个分量为 $\sqrt[]{a_{ii}^2 + a_{ij}^2}$, 第 $j$ 个分量为0. 则令 $T_i$ 为将 $a_i$ 的第 $i$ 个分量变为 $\sqrt[]{a_{ii}^2 + \cdots a_{in}^2} $, 第 $j > i$ 个分量为0 的Givens矩阵. 令 $T = T_n \cdots T_1$, 则 $TA = U$.
Householder矩阵 可以实现相同的功能.
</details>