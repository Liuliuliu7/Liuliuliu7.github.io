<!DOCTYPE html><html><head>
      <title>第四章</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      
        <script type="text/javascript">
          window.MathJax = ({"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"options":{},"loader":{}});
        </script>
        <script type="text/javascript" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" charset="UTF-8"></script>
        
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
.markdown-preview.markdown-preview {
  /* 样式化按钮 */
  /* 当鼠标悬停在按钮上时改变背景颜色 */
  /* 响应式设计：针对移动端 */
}
.markdown-preview.markdown-preview body {
  line-height: 175%;
}
.markdown-preview.markdown-preview #toggleProofs {
  font: 0.8em;
  font-style: italic;
  padding: 5px 5px;
  background-color: #4CAF50;
  color: white;
  border: none;
  border-radius: 5px;
  cursor: pointer;
  float: right;
}
.markdown-preview.markdown-preview #toggleProofs:hover {
  background-color: #45a049;
}
.markdown-preview.markdown-preview details {
  border: 2px solid #e1eaed;
  /* 蓝色边框 */
  border-radius: 10px;
  /* 圆角 */
  padding: 0px 8px 0px 8px;
  /* 内边距 */
  margin-bottom: 8px;
  /* 底部外边距 */
  transition: box-shadow 0.3s ease;
  /* 阴影过渡效果 */
  line-height: 200%;
  /* 设置行间距为当前字体大小的125% */
}
.markdown-preview.markdown-preview details:hover {
  border: 2px solid #90c1f4;
  /* 蓝色边框 */
  border-radius: 10px;
  /* 圆角 */
  padding: 0px 8px 0px 8px;
  /* 内边距 */
  margin-bottom: 8px;
  /* 底部外边距 */
  transition: box-shadow 0.3s ease;
  /* 阴影过渡效果 */
  line-height: 200%;
  /* 设置行间距为当前字体大小的125% */
}
.markdown-preview.markdown-preview summary {
  font-weight: bold;
  font-style: italic;
}
.markdown-preview.markdown-preview .callout {
  font-weight: bold;
  font-size: medium;
  font-style: italic;
  color: #005792;
  /* 深蓝色 */
  background-color: #E7F7FF;
  /* 浅蓝色背景 */
  padding: 5px 5px;
  margin-bottom: 10px;
  border-radius: 5px;
  /* 添加圆角 */
}
.markdown-preview.markdown-preview .fixed-toc {
  position: fixed;
  /* 使用固定定位 */
  left: 0;
  /* 贴合窗口左侧 */
  top: 0;
  /* 贴合窗口顶部 */
  max-width: 400px;
  /* 目录最大宽度 */
  overflow-y: auto;
  /* 如果内容超出高度，则显示滚动条 */
  height: 100%;
  /* 目录的高度 */
  padding: 10px;
  /* 内边距 */
  z-index: -100;
  /* 使目录在最底层 */
}
@media (max-width: 768px) {
  .markdown-preview.markdown-preview .fixed-toc {
    padding: 10px;
    /* 内边距 */
    position: inherit;
    /* 取消固定定位 */
    z-index: 100;
    /* 使目录在最顶层 */
  }
}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h4 id="矩阵分析">矩阵分析 </h4>
<p><span class="callout">4.1.1 Definition: 向量范数定义</span></p>
<blockquote>
<p>设<span class="mathjax-exps">$V$</span>是数域<span class="mathjax-exps">$F$</span>上的线性空间，<span class="mathjax-exps">$\|x\|$</span>是以<span class="mathjax-exps">$V$</span>中向量<span class="mathjax-exps">$x$</span>为自变量的实值函数，若满足以下三条性质：<br>
(1) 正定性（或非负性）: <span class="mathjax-exps">$\|x\|\geqslant 0, \|x\|=0$</span> 当且仅当 <span class="mathjax-exps">$x=0$</span>；<br>
(2) 齐次性: <span class="mathjax-exps">$\forall k\in F$</span> 和 <span class="mathjax-exps">$x\in V, \|kx\|=|k|\|x\|$</span>；<br>
(3) 三角不等式: <span class="mathjax-exps">$\forall x, y\in V, \|x+y\|\leqslant \|x\|+\|y\|(\text{or} |\|x\| - \|y\|| \leqslant \|x - y\|)$</span>，<br>
则称 <span class="mathjax-exps">$\|x\|$</span> 是向量<span class="mathjax-exps">$x$</span>的范数，<span class="mathjax-exps">$V$</span>是数域<span class="mathjax-exps">$F$</span>上的赋范线性空间，记为 <span class="mathjax-exps">$(V,\|\cdot\|)$</span>。</p>
</blockquote>
<p>常见的向量范数有：<span class="mathjax-exps">$1$</span>范数 、<span class="mathjax-exps">$2$</span>范数、<span class="mathjax-exps">$\infty$</span> 范数、<span class="mathjax-exps">$p$</span> 范数。定义如下：<br>
<span class="mathjax-exps">$\forall x = (x_1, x_2, \ldots, x_n)^\top \in \mathbb{C}^n$</span>,</p>
<p></p><div class="mathjax-exps">$$\begin{gathered} \|x\|_1 = \sum_{i=1}^{n} |x_i| \\ \|x\|_\infty = \max_{1 \leq i \leq n} |x_i| \\ \|x\|_2 = \left( \sum_{i=1}^{n} |x_i|^2 \right)^{\frac{1}{2}} \\ \|x\|_p = \left( \sum_{i=1}^{n} |x_i|^p \right)^{\frac{1}{p}} \end{gathered}$$</div><p></p>
<p><span class="callout">4.1.2 Example: 基于坐标的范数</span></p>
<blockquote>
<p>设向量组 <span class="mathjax-exps">$\varepsilon_1, \varepsilon_2, \ldots, \varepsilon_n$</span> 是 <span class="mathjax-exps">$n$</span> 维线性空间 <span class="mathjax-exps">$V$</span> 的一组基，<span class="mathjax-exps">$V$</span> 中任意向量 <span class="mathjax-exps">$\alpha$</span> 在这组基下的坐标为 <span class="mathjax-exps">$x = (x_1, x_2, \ldots, x_n)^\top$</span>。由此，我们可定义向量 <span class="mathjax-exps">$\alpha$</span> 的范数为</p>
<p></p><div class="mathjax-exps">$$\|\alpha\| \stackrel{\text{def}}{=} \sqrt{\sum_{i=1}^{n} |x_i|^2}$$</div><p></p>
</blockquote>
<p><span class="callout">4.1.3 Example: p-范数</span></p>
<blockquote>
<p>设 <span class="mathjax-exps">$1\leqslant p\leqslant\infty$</span>, <span class="mathjax-exps">$\forall x=\left(x_1, x_2,\cdots, x_n\right)^{\text{T}}\in \mathbb{C}^n$</span>，定义<br>
</p><div class="mathjax-exps">$$\|x\|_p=\left(\sum_{i=1}^n\left|x_i\right|^p\right)^{\frac{1}{p}}$$</div><p></p>
<p>则 <span class="mathjax-exps">$\|x\|_p$</span> 是向量 <span class="mathjax-exps">$x$</span> 的范数，称为 <span class="mathjax-exps">$p$</span>-范数。</p>
</blockquote>
<p><span class="callout">4.1.4 Lemma: Holder 与 Minkowski 不等式</span></p>
<blockquote>
<p>(1) Holder 不等式. 设 <span class="mathjax-exps">$p, q&gt;1$</span> 且 <span class="mathjax-exps">$\frac{1}{p}+\frac{1}{q}=1$</span>，则对任意 <span class="mathjax-exps">$x=\left(x_1, x_2,\cdots, x_n\right)^{\text{T}}\in \mathbb{C}^n$</span> 和 <span class="mathjax-exps">$y=\left(y_1, y_2,\cdots, y_n\right)^{\text{T}}\in \mathbb{C}^n$</span>，有<br>
</p><div class="mathjax-exps">$$\sum_{i=1}^n\left|x_i y_i\right|\leqslant\left(\sum_{i=1}^n\left|x_i\right|^p\right)^{\frac{1}{p}}\left(\sum_{i=1}^n\left|y_i\right|^q\right)^{\frac{1}{q}}$$</div><p></p>
<p>(2) Minkowski 不等式. <span class="mathjax-exps">$\forall x=\left(x_1, x_2,\cdots, x_n\right)^{\text{T}}\in \mathbb{C}^n$</span> 和 <span class="mathjax-exps">$y=\left(y_1, y_2,\cdots, y_n\right)^{\text{T}}\in \mathbb{C}^n$</span> 以及 <span class="mathjax-exps">$p\geqslant 1$</span>，则<br>
</p><div class="mathjax-exps">$$\left(\sum_{i=1}^n\left|x_i+y_i\right|^p\right)^{\frac{1}{p}}\leqslant\left(\sum_{i=1}^n\left|x_i\right|^p\right)^{\frac{1}{p}}+\left(\sum_{i=1}^n\left|y_i\right|^p\right)^{\frac{1}{p}}$$</div><p></p>
</blockquote>
<p><span class="callout">4.1.5 Example: 加权范数或椭圆范数</span></p>
<blockquote>
<p>设 <span class="mathjax-exps">$A\in \mathbb{C}^{n\times n}$</span> 是正定 Hermite 矩阵, <span class="mathjax-exps">$\forall x\in \mathbb{C}^n$</span>, 定义 <span class="mathjax-exps">$\|x\|_A=\sqrt{x^{H} A x}$</span>，则 <span class="mathjax-exps">$\|x\|_A$</span> 是向量范数，常称为加权范数或椭圆范数。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>由 <a href="#th3.3.1">Cholesky 分解</a>知，存在可逆矩阵 <span class="mathjax-exps">$W$</span> 使得 <span class="mathjax-exps">$A=W^{H} W$</span>。因此，<br>
</p><div class="mathjax-exps">$$\|x\|_A=\sqrt{x^{H} A x}=\|Wx\|_2$$</div><p></p>
<p>由式(4.1.6)容易证明正定性和齐次性。下面证明三角不等式：</p>
<p></p><div class="mathjax-exps">$$\|x+y\|_A=\|W(x+y)\|_2\leqslant\|W x\|_2+\|W y\|_2=\|x\|_A+\|y\|_A$$</div><p></p>
<p>综上所述，<span class="mathjax-exps">$\|x\|_A$</span> 是向量 <span class="mathjax-exps">$x$</span> 的范数。</p>
</details>
<p><span class="callout">4.1.1 Theorem: 线性空间的范数连续</span></p>
<blockquote>
<p>线性空间 <span class="mathjax-exps">$V$</span> 中任一范数 <span class="mathjax-exps">$\|x\|$</span> 都是其坐标的连续函数。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>设 <span class="mathjax-exps">$V$</span> 是 <span class="mathjax-exps">$n$</span> 维线性空间，<span class="mathjax-exps">$\epsilon_1,\cdots,\epsilon_n$</span> 是 <span class="mathjax-exps">$V$</span> 中一组基，则对 <span class="mathjax-exps">$V$</span> 中任意向量 <span class="mathjax-exps">$x$</span> 和 <span class="mathjax-exps">$y$</span> 有<br>
</p><div class="mathjax-exps">$$\begin{align*}&amp; x=\xi_1\epsilon_1+\cdots+\xi_n\epsilon_n=\left[\epsilon_1\quad\cdots\quad\epsilon_n\right]\xi\\ &amp; y=\eta_1\epsilon_1+\cdots+\eta_n\epsilon_n=\left[\epsilon_1\quad\cdots\quad\epsilon_n\right]\eta\end{align*}$$</div><p></p>
<p>式中：<span class="mathjax-exps">$\xi=\left(\xi_1,\cdots,\xi_n\right)^{\text{T}}$</span> 和 <span class="mathjax-exps">$\eta=\left(\eta_1,\cdots,\eta_n\right)^{\text{T}}$</span> 分别是向量 <span class="mathjax-exps">$x$</span> 和 <span class="mathjax-exps">$y$</span> 在基 <span class="mathjax-exps">$\epsilon_1,\cdots,\epsilon_n$</span> 下的坐标。<br>
由 <span class="mathjax-exps">$\|x\|=\|[\epsilon_1\cdots\epsilon_n]\xi\|$</span> 知，任一范数 <span class="mathjax-exps">$\|x\|$</span> 都是向量 <span class="mathjax-exps">$x$</span> 坐标的函数，故<br>
</p><div class="mathjax-exps">$$\begin{align*}&amp;\|x\|-\|y\|\leqslant\|x-y\|=\left\|\sum_{i=1}^n\left(\xi_i-\eta_i\right)\epsilon_i\right\|\\ &amp;\leqslant\sum_{i=1}^n\left|\left(\xi_i-\eta_i\right)\right|\left\|\epsilon_i\right\|\leqslant\kappa\left[\sum_{i=1}^n\left|\left(\xi_i-\eta_i\right)\right|^2\right]^{\frac{1}{2}}\end{align*}$$</div><p></p>
<p>式中：<span class="mathjax-exps">$\kappa=\left(\sum_{i=1}^n\left\|\epsilon_i\right\|^2\right)^{\frac{1}{2}}$</span> 是正常数。<br>
当 <span class="mathjax-exps">$\xi_i\rightarrow\eta_i(i=1,\cdots, n)$</span> 时，<span class="mathjax-exps">$|| x\|-\| y\||\rightarrow 0$</span>，即 <span class="mathjax-exps">$\| x\|\rightarrow\| y\|$</span>。因此，<span class="mathjax-exps">$\| x\|$</span> 是其坐标 <span class="mathjax-exps">$\xi_j$</span> 的连续函数。证毕。</p>
</details>
<p>{注}：由于连续函数在有界闭集上一定有最大值和最小值，故研究赋范线性空间上的连续函数或变换的一个重要技巧就是设法将函数的定义域限制或转移到“单位圆”上，即 <span class="mathjax-exps">$\|x\|=1$</span> 的集合。</p>
<p><span class="callout">4.1.2 Definition: 等价范数</span></p>
<blockquote>
<p>设 <span class="mathjax-exps">$V$</span> 是数域 <span class="mathjax-exps">$F$</span> 上的有限维线性空间，<span class="mathjax-exps">$\|x\|_\alpha$</span> 和 <span class="mathjax-exps">$\|x\|_\beta$</span> 是 <span class="mathjax-exps">$V$</span> 中任意两个向量范数。若存在正数 <span class="mathjax-exps">$k_1$</span> 和 <span class="mathjax-exps">$k_2$</span> 使得 <span class="mathjax-exps">$\forall x\in V$</span>，都有<br>
</p><div class="mathjax-exps">$$k_1\|x\|_\beta\leqslant\|x\|_\alpha\leqslant k_2\|x\|_\beta$$</div><p></p>
<p>则称 <span class="mathjax-exps">$\|x\|_\alpha$</span> 与 <span class="mathjax-exps">$\|x\|_\beta$</span> 是等价的。</p>
</blockquote>
<p><span class="callout">4.1.2 Theorem: 有限维线性空间范数等价</span></p>
<blockquote>
<p>有限维线性空间中的任意向量范数都是等价的。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>设向量组 <span class="mathjax-exps">$\epsilon_1,\cdots,\epsilon_n$</span> 是线性空间 <span class="mathjax-exps">$V$</span> 中一组基，则对 <span class="mathjax-exps">$V$</span> 中任意向量 <span class="mathjax-exps">$x$</span>，有<br>
</p><div class="mathjax-exps">$$x=\xi_1\epsilon_1+\cdots+\xi_n\epsilon_n=\left[\epsilon_1\quad\cdots\quad\epsilon_n\right]\xi$$</div><p></p>
<p>式中：<span class="mathjax-exps">$\xi=\left(\xi_1,\cdots,\xi_n\right)^{\text{T}}$</span> 是向量 <span class="mathjax-exps">$x$</span> 在基 <span class="mathjax-exps">$\epsilon_1,\cdots,\epsilon_n$</span> 下的坐标。</p>
<p>令 <span class="mathjax-exps">$\|x\|_\alpha$</span> 与 <span class="mathjax-exps">$\|x\|_\beta$</span> 是 <span class="mathjax-exps">$V$</span> 中的两个不同范数。当 <span class="mathjax-exps">$x=\theta$</span> 时，<span class="mathjax-exps">$k_1\|x\|_\beta\leqslant\|x\|_\alpha\leqslant k_2\|x\|_\beta$</span> 显然成立。<br>
现考察 <span class="mathjax-exps">$x\neq\theta$</span> 的情况。由定理 4.1.1 知，<span class="mathjax-exps">$\|x\|_\alpha$</span> 与 <span class="mathjax-exps">$\|x\|_\beta$</span> 均是坐标 <span class="mathjax-exps">$\xi$</span> 的连续函数。定义函数 <span class="mathjax-exps">$f(\xi)$</span> 和集合 <span class="mathjax-exps">$S$</span>：</p>
<p></p><div class="mathjax-exps">$$\begin{gathered} f(\xi)=\frac{\|x\|_a}{\|x\|_\beta}\\ S=\left\{\eta\in F^n\left|\sum_{i=1}^n\left|\eta_i\right|^2=1\right.\right\} \end{gathered}$$</div><p></p>
<p>则 <span class="mathjax-exps">$f(\xi)$</span> 也是 <span class="mathjax-exps">$\xi$</span> 的连续函数,集合 <span class="mathjax-exps">$S$</span> 是 <span class="mathjax-exps">$F^n$</span> 中的一个单位超球面且为有界闭集.</p>
<p>注意到:</p>
<p></p><div class="mathjax-exps">$$\frac{\|x\|_\alpha}{\left(\sum_{i=1}^n |\xi_i|^2\right)^{\frac{1}{2}}} = \left\|\frac{\xi_1 \epsilon_1 + \cdots + \xi_n \epsilon_n}{\left(\sum_{i=1}^n |\xi_i|^2\right)^{\frac{1}{2}}}\right\|_\alpha = \|[ \epsilon_1 \cdots \epsilon_n ] \xi'\|_\alpha$$</div><p></p>
<p></p><div class="mathjax-exps">$$\frac{\|x\|_\beta}{\left(\sum_{i=1}^n |\xi_i|^2\right)^{\frac{1}{2}}} = \left\|\frac{\xi_1 \epsilon_1 + \cdots + \xi_n \epsilon_n}{\left(\sum_{i=1}^n |\xi_i|^2\right)^{\frac{1}{2}}}\right\|_\beta = \|[ \epsilon_1 \cdots \epsilon_n ] \xi'\|_\beta$$</div><p></p>
<p>式中:</p>
<p></p><div class="mathjax-exps">$$\xi'=\left(\frac{\xi_1}{\left(\sum_{i=1}^n\left|\xi_i\right|^2\right)^{\frac{1}{2}}},\cdots,\frac{\xi_n}{\left(\sum_{i=1}^n\left|\xi_i\right|^2\right)^{\frac{1}{2}}}\right)^T\in S$$</div><p></p>
<p>此时，<span class="mathjax-exps">$f(\xi)$</span> 等价为</p>
<p></p><div class="mathjax-exps">$$\begin{align*} &amp; f\left(\xi'\right)=\frac{\sum_{i=1}^n\left|\xi_i\right|^2}{\|x\|_\beta} \end{align*}$$</div><p></p>
<p>由于连续函数 <span class="mathjax-exps">$f\left(\xi'\right)$</span> 在有界闭集 <span class="mathjax-exps">$S$</span> 上必有最大值 <span class="mathjax-exps">$k_2$</span> 和最小值 <span class="mathjax-exps">$k_1$</span> ,则 <span class="mathjax-exps">$k_1\|x\|_\beta\leqslant\|x\|_\alpha\leqslant k_2\|x\|_\beta$</span>。<br>
证毕。</p>
</details>
<p><span class="callout">4.1.1 Proposition: 向量等价范数的性质</span></p>
<blockquote>
<p>设 <span class="mathjax-exps">$V$</span> 是数域 <span class="mathjax-exps">$F$</span> 上的有限维线性空间，若向量范数 <span class="mathjax-exps">$\|x\|_\alpha$</span> 与 <span class="mathjax-exps">$\|x\|_\beta$</span> 等价，则满足<br>
(1) 自反性：<span class="mathjax-exps">$1\cdot\|x\|_\alpha\leqslant\|x\|_\alpha\leqslant 1\cdot\|x\|_\alpha;$</span><br>
(2) 对称性：<span class="mathjax-exps">$\frac{1}{k_2}\|x\|_\alpha\leqslant\|x\|_\beta\leqslant\frac{1}{k_1}\|x\|_\alpha;$</span><br>
(3) 传递性：若 <span class="mathjax-exps">$\|x\|_\beta$</span> 与 <span class="mathjax-exps">$\|x\|_\gamma$</span> 等价，则向量范数 <span class="mathjax-exps">$\|x\|_\alpha$</span> 与 <span class="mathjax-exps">$\|x\|_\gamma$</span> 等价。</p>
</blockquote>
<p><span class="callout">4.2.1 Definition: 矩阵向量范数</span></p>
<blockquote>
<p>对任意矩阵 <span class="mathjax-exps">$A\in \mathbb{C}^{m\times n}$</span>，定义 <span class="mathjax-exps">$\|A\|$</span> 是对应以矩阵 <span class="mathjax-exps">$A$</span> 为自变量的实值函数，且满足以下三条性质：<br>
(1) 正定性（或非负性）: <span class="mathjax-exps">$\|A\|\geqslant 0$</span>，当且仅当 <span class="mathjax-exps">$A=O$</span> 时，有 <span class="mathjax-exps">$\|A\|=0$</span>;<br>
(2) 齐次性：<span class="mathjax-exps">$\forall k\in \mathbb{C}, \|kA\|=|k|\|A\|$</span>;<br>
(3) 三角不等式：<span class="mathjax-exps">$\forall A,B\in \mathbb{C}^{m\times n}$</span>，有 <span class="mathjax-exps">$\|A+B\|\leqslant\|A\|+\|B\|$</span>.<br>
则称 <span class="mathjax-exps">$\|A\|$</span> 是矩阵 <span class="mathjax-exps">$A$</span> 的向量范数.</p>
</blockquote>
<p><span class="callout">4.2.1 Example: 常见矩阵向量范数</span></p>
<blockquote>
<p>设 <span class="mathjax-exps">$A=\left(a_{ij}\right)\in \mathbb{C}^{m\times n}$</span>，则</p>
<p></p><div class="mathjax-exps">$$\begin{align*} \|A\|_{v1} &amp;= \sum_{i=1}^m\sum_{j=1}^n\left|a_{ij}\right|, \\ \|A\|_{v\infty} &amp;= \max_{\forall i, j}\left|a_{ij}\right|, \\ \|A\|_{v2} &amp;= \left(\sum_{i=1}^m\sum_{j=1}^n\left|a_{ij}\right|^2\right)^{\frac{1}{2}}, \\ \|A\|_{vp} &amp;= \left(\sum_{i=1}^m\sum_{j=1}^n\left|a_{ij}\right|^p\right)^{\frac{1}{p}}, \quad p\geqslant 1 \end{align*}$$</div><p></p>
</blockquote>
<p>{注}：矩阵向量范数的定义与向量范数的相同，只是将向量 <span class="mathjax-exps">$x$</span> 替换为矩阵 <span class="mathjax-exps">$A$</span>。</p>
<p><span class="callout">4.2.2 Definition: 矩阵范数</span></p>
<blockquote>
<p>对任意矩阵 <span class="mathjax-exps">$A\in \mathbb{C}^{m\times n}$</span>，定义 <span class="mathjax-exps">$\|A\|$</span> 均是对应以矩阵 <span class="mathjax-exps">$A$</span> 为自变量的实值函数，且满足以下四条性质：<br>
(1) 正定性：<span class="mathjax-exps">$\|A\|\geqslant 0$</span>，当且仅当 <span class="mathjax-exps">$A=O$</span> 时，有 <span class="mathjax-exps">$\|A\|=0$</span>;<br>
(2) 齐次性：<span class="mathjax-exps">$\forall k\in \mathbb{C}, \|kA\|=|k|\|A\|$</span>;<br>
(3) 三角不等式：<span class="mathjax-exps">$\|A+B\|\leqslant\|A\|+\|B\|$</span>;<br>
(4) 矩阵乘法相容性：<span class="mathjax-exps">$\|AB\|\leqslant\|A\|\|B\|$</span>.<br>
则称 <span class="mathjax-exps">$\|A\|$</span> 是矩阵 <span class="mathjax-exps">$A$</span> 的矩阵范数。</p>
</blockquote>
<p><span class="callout">4.2.2 Example: Frobenius 范数</span></p>
<blockquote>
<p>设 <span class="mathjax-exps">$A=\left(a_{ij}\right)\in \mathbb{C}^{m\times n}$</span>，则<br>
</p><div class="mathjax-exps">$$\|A\|_{v2}=\left(\sum_{i=1}^m\sum_{j=1}^n\left|a_{ij}\right|^2\right)^{\frac{1}{2}}=\left[\operatorname{tr}\left(A^{H} A\right)\right]^{\frac{1}{2}} = \sqrt[]{\sum_{i=1}^{n} \delta _i}$$</div><p></p>
<p>是 <span class="mathjax-exps">$A$</span> 的矩阵范数。其中 <span class="mathjax-exps">$\delta_i$</span> 是 <span class="mathjax-exps">$A^{H} A$</span> 的奇异值。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>(1)~(3) 的证明与矩阵向量范数相同，下面证明矩阵乘法相容性。<br>
(4) 乘法相容性：<span class="mathjax-exps">$\|AB\|_{v2}^2=\sum_{i=1}^m\sum_{j=1}^p\left|c_{ij}\right|^2$</span>，其中</p>
<p></p><div class="mathjax-exps">$$\begin{gathered} \left|c_{ij}\right|^2=\left|\sum_{k=1}^n a_{ik} b_{kj}\right|^2\leqslant\left(\sum_{k=1}^n\left|a_{ik} b_{kj}\right|\right)^2 \\ \leqslant\left(\sum_{k=1}^n\left|a_{ik}\right|^2\right)\left(\sum_{k=1}^n\left|b_{kj}\right|^2\right) \\ \left\|AB\right\|_{v2}^2\leqslant\sum_{i, j}\left[\left(\sum_{k=1}^n\left|a_{ik}\right|^2\right)\left(\sum_{k=1}^n\left|b_{kj}\right|^2\right)\right]=\left\|A\right\|_{v2}^2\left\|B\right\|_{v2}^2 \end{gathered}$$</div><p></p>
<p>因此，<span class="mathjax-exps">$\|A\|_{v2}$</span> 是 <span class="mathjax-exps">$A$</span> 的矩阵范数。证毕。</p>
</details>
<p>{注}：<span class="mathjax-exps">\(\|A\|\_{v2}\)</span> 范数称为 Frobenius 范数，简称为<span class="mathjax-exps">$F$</span>-范数，并常记为<span class="mathjax-exps">\(\|A\|\_F\)</span>.</p>
<p><span class="callout">4.2.3 Theorem: F 范数的性质</span></p>
<blockquote>
<p>设 <span class="mathjax-exps">$A=\left(a_{ij}\right)\in \mathbb{C}^{m\times n}$</span> 和 <span class="mathjax-exps">$x\in \mathbb{C}^n$</span>，则<br>
(1) <span class="mathjax-exps">$\|UA\|_F=\|AV\|_F=\|UAV\|_F=\|A\|_F$</span>，其中 <span class="mathjax-exps">$U$</span> 和 <span class="mathjax-exps">$V$</span> 是酉矩阵；<br>
(2) </p><div class="mathjax-exps">$$\|A\|_F^2=\sum_{i=1}^n\|\beta_i\|_2^2 =\sum_{i=1}^m\|\alpha_i\|_2^2$$</div><br>
其中矩阵 <span class="mathjax-exps">$A$</span> 按列分块，记为<br>
<div class="mathjax-exps">$$A=\left[\beta_1\cdots\beta_n\right]$$</div><p></p>
<p>或矩阵 <span class="mathjax-exps">$A$</span> 按行分块，记为<br>
</p><div class="mathjax-exps">$$A=\left[\begin{array}{c}\alpha_1^T\\ \vdots\\ \alpha_m^T\end{array}\right]$$</div><p></p>
<p>(3) <span class="mathjax-exps">$\|Ax\|_2\leqslant\|A\|_F\|x\|_2.$</span></p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>只对(3)进行证明。<br>
对矩阵 <span class="mathjax-exps">\(A\)</span> 行分块得</p>
<p></p><div class="mathjax-exps">$$\|A x\|_2=\left\|\begin{array}{c} \alpha_1^{T} x\\ \vdots\\ \alpha_m^{T} x \end{array}\right\|_2=\left(\sum_{i=1}^m\left|\alpha_i^{T} x\right|^2\right)^{\frac{1}{2}}$$</div><p></p>
<p>根据 Cauchy 不等式得 <span class="mathjax-exps">\(\left|\alpha_i^{T} x\right|\leqslant\left\|\alpha_i\right\|\_2\| x\|\_2\)</span>, 并将其代入上式得</p>
<p></p><div class="mathjax-exps">$$\|A x\|_2\leqslant\left(\sum_{i=1}^m\|\alpha_i\|_2\right)\|x\|_2=\|A\|_F\|x\|_2$$</div><p></p>
</details>
<p><span class="callout">4.2.3 Example: 构造矩阵范数</span></p>
<blockquote>
<p>设 <span class="mathjax-exps">$A\in \mathbb{C}^{n\times n}, \|\cdot\|$</span> 是某一给定矩阵范数。定义<br>
</p><div class="mathjax-exps">$$\|A\|_m = \|P^{-1}AP\|$$</div><p></p>
<p>则 <span class="mathjax-exps">$\|\cdot\|_m$</span> 是矩阵范数，其中 <span class="mathjax-exps">$P$</span> 是 <span class="mathjax-exps">$n$</span> 阶可逆矩阵。</p>
</blockquote>
<p><span class="callout">4.3.1 Definition: 向量范数与矩阵范数相容</span></p>
<blockquote>
<p>若对任意 <span class="mathjax-exps">$A\in \mathbb{C}^{m\times n}$</span> 和 <span class="mathjax-exps">$x\in \mathbb{C}^n$</span>，向量范数 <span class="mathjax-exps">$\|x\|_v$</span> 与矩阵范数 <span class="mathjax-exps">$\|A\|_m$</span> 满足<br>
</p><div class="mathjax-exps">$$\|Ax\|_v \leqslant \|A\|_m \|x\|_v$$</div><p></p>
<p>则称向量范数 <span class="mathjax-exps">$\|x\|_v$</span> 与矩阵范数 <span class="mathjax-exps">$\|A\|_m$</span> 相容。</p>
</blockquote>
<p><span class="callout">4.3.1 Theorem: 相容向量范数存在性</span></p>
<blockquote>
<p>设<span class="mathjax-exps">$\|A\|_m$</span>是<span class="mathjax-exps">$\mathbb{C}^{n \times n}$</span>的一个矩阵范数，则必存在<span class="mathjax-exps">$\mathbb{C}^n$</span>上与之相容的向量范数。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>取定非零向量 <span class="mathjax-exps">$\alpha=\left(\alpha_1,\cdots,\alpha_n\right)^{T}\in \mathbb{C}^n$</span> , 则对任意向量 <span class="mathjax-exps">$x=\left(x_1,\cdots, x_n\right)^{T}\in \mathbb{C}^n$</span> , 定义</p>
<p></p><div class="mathjax-exps">$$\|x\|_v=\left\|x\alpha^{T}\right\|_m$$</div><p></p>
<p>因此:<br>
(1) 正定性: <span class="mathjax-exps">$\|x\|_v\geqslant 0$</span> 成立; <span class="mathjax-exps">$\|x\|_v=0$</span> 当且仅当 <span class="mathjax-exps">$x\alpha^{T}=O$</span> , 即</p>
<p></p><div class="mathjax-exps">$$a_i x_j=0,\quad i, j=1,\cdots, n$$</div><p></p>
<p>上式成立的充分必要条件为 <span class="mathjax-exps">$x=0$</span>.</p>
<p>(2) 齐次性: <span class="mathjax-exps">$\forall k\in \mathbb{C},\|k x\|_v=|k|\|x\|_v.$</span><br>
(3) 三角不等式: 设 <span class="mathjax-exps">$x=\left(x_1,\cdots, x_n\right)^{T}\in \mathbb{C}^n$</span> 和 <span class="mathjax-exps">$y=\left(y_1, y_2,\cdots, y_n\right)^{T}\in \mathbb{C}^n$</span> , 则</p>
<p></p><div class="mathjax-exps">$$\|x+y\|_v=\|x\alpha^{T}+y\alpha^{T}\|_m\leqslant\left\|x\alpha^{T}\right\|_m+\left\|y\alpha^{T}\right\|_m=\|x\|_v+\left\|y\right\|_v$$</div><p></p>
<p>(4) 相容性: <span class="mathjax-exps">$\forall A\in \mathbb{C}^{n\times n},\left\|A x\right\|_v=\left\|A x\alpha^{T}\right\|_m\leqslant\left\|A\right\|_m\left\|x\alpha^{T}\right\|_m=\left\|A\right\|_m\|x\|_v$</span></p>
</details>
<p><span class="callout">4.3.2 Theorem: 算子范数存在性</span></p>
<blockquote>
<p>设<span class="mathjax-exps">$\|x\|_v$</span>是<span class="mathjax-exps">$\mathbb{C}^n$</span>上的一个向量范数，对任意矩阵<span class="mathjax-exps">$A \in \mathbb{C}^{m \times n}$</span>，定义</p>
<p></p><div class="mathjax-exps">$$\|A\| = \max_{\|x\|_v = 1} \|Ax\|_v$$</div><p></p>
<p>则<span class="mathjax-exps">$\|A\|$</span>是一个与<span class="mathjax-exps">$\|x\|_v$</span>相容的矩阵范数，称该矩阵范数是从属于向量范数<span class="mathjax-exps">$\|\cdot\|_v$</span>的算子范数或由向量范数<span class="mathjax-exps">$\|\cdot\|_v$</span>诱导的矩阵范数。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>(1) 正定性: <span class="mathjax-exps">$\|A\|\geqslant 0$</span> 显然成立, 且有 <span class="mathjax-exps">$A=O\Rightarrow\|A\|=0$</span>. <span class="mathjax-exps">$\|A\|=0$</span> 意味着对满足 <span class="mathjax-exps">$\|x\|_v=1$</span> 的任意向量 x 都有 <span class="mathjax-exps">$A x=0$</span>. 此时, 齐次线性方程组 <span class="mathjax-exps">$A x=0$</span> 的解空间的维数为 n. 根据定理 2.3.6 知, <span class="mathjax-exps">$\operatorname{rank}(A)=0$</span>. 因此, <span class="mathjax-exps">$A=O$</span>.</p>
<p>(2) 齐次性: <span class="mathjax-exps">$\forall k\in \mathbb{C}$</span>, 有</p>
<p></p><div class="mathjax-exps">$$\|kA\|=\max_{\|x\|_v=1}\|k A x\|_v=|k|\max_{\|x\|_v=1}\|Ax\|_v=|k|\|A\|$$</div><p></p>
<p>(3) 三角不等式: <span class="mathjax-exps">$\forall B\in \mathbb{C}^{m\times n}$</span>, 必存在 <span class="mathjax-exps">$\|x\|_v=1$</span> 的向量 <span class="mathjax-exps">$x_0\in \mathbb{C}^n$</span> 满足</p>
<p></p><div class="mathjax-exps">$$\begin{align*} &amp;\|A+B\|=\|(A+B) x_0\|_v\leqslant\|A x_0\|_v+\|B x_0\|_v\\ &amp;\leqslant\max_{\|x\|_v=1}\|A x\|_v+\max_{\|x\|_v=1}\|B x\|_v=\|A\|+\|B\| \end{align*}$$</div><p></p>
<p>(4) 矩阵乘法相容性: 对任意矩阵 <span class="mathjax-exps">$B\in \mathbb{C}^{m\times p}$</span> 和 <span class="mathjax-exps">$C\in \mathbb{C}^{n\times p}$</span>, 必存在 <span class="mathjax-exps">$\|y_0\|=1$</span> 的 <span class="mathjax-exps">$y_0\in \mathbb{C}^n$</span> 满足</p>
<p></p><div class="mathjax-exps">$$\|BC\|=\|(BC) y_0\|_v$$</div><p></p>
<p>若 <span class="mathjax-exps">$\|C y_0\|_v=0$</span>, 则 <span class="mathjax-exps">$\|B C\|=0$</span>. 性质(4)成立.</p>
<p>若 <span class="mathjax-exps">$\|C y_0\|_v\neq 0$</span>, 则有</p>
<p></p><div class="mathjax-exps">$$\begin{align*} \|BC\|=\|(BC) y_0\|_v&amp;=\left\|B\left(\frac{1}{\left\|C y_0\right\|_v} C y_0\right)\|C y_0\|_v\right\|_v\\ &amp;=\left\|B\left(\frac{1}{\left\|C y_0\right\|_v} C y_0\right)\right\|_v\|C y_0\|_v\\ &amp;\leqslant\|B\|\left\|C y_0\right\|_v\leqslant\|B\|\left\|C\right\| \end{align*}$$</div><p></p>
<p>(5) 矩阵范数与向量范数的相容性: 若 <span class="mathjax-exps">$x=0,\|Ax\|_v=\|A\|\|x\|_v=0$</span>. 若 <span class="mathjax-exps">$x\neq 0$</span>, 有</p>
<p></p><div class="mathjax-exps">$$\|A x\|_v=\left\|A\frac{1}{\|x\|_v} x\right\|_v\leqslant\|A\|\|x\|_v$$</div><p></p>
<p>因此, 矩阵范数是从属于向量范数 <span class="mathjax-exps">$\|\cdot\|$</span> 的算子范数.</p>
</details>
<p>算子范数也可用如下等价定义式：<br>
</p><div class="mathjax-exps">\[\|A\| = \max\_{\|x\|\_v \neq 0} \frac{\|Ax\|\_v}{\|x\|\_v}\]</div><p></p>
<p>{注}：由上可知，对于一个矩阵范数，必存在一个与之相容的向量范数；对于一个向量范数，必存在一个与之相容的矩阵范数。<br>
常见的向量范数有：<span class="mathjax-exps">$1$</span>范数 、<span class="mathjax-exps">$2$</span>范数、<span class="mathjax-exps">$\infty$</span> 范数，则其对应的算子范数为：</p>
<p></p><div class="mathjax-exps">$$\begin{align*} \|A\|_1 &amp;= \max_{\|x\|_1=1} \|Ax\|_1 = \max_{1\leq j\leq n}\sum_{i=1}^m|a_{ij}| &amp;\quad(列和范数) \\ \|A\|_2 &amp;= \max_{\|x\|_2=1} \|Ax\|_2 =\sqrt{\sigma_{\max }(A^HA)} &amp;\quad(谱范数)\\ \|A\|_\infty &amp;=\max_{\|x\|_\infty=1} \|Ax\|_\infty = \max_{1\leq i\leq m}\sum_{j=1}^n|a_{ij}| &amp;\quad(行和范数) \end{align*}$$</div><p></p>
<p>最后一个等号的证明如下：</p>
<details open="">
    <summary>Proof:</summary>
</details>
<p>{注}：矩阵范数与向量范数相容中定义的不等式是为了不等式的放缩，而显然相容于一个向量范数的矩阵范数不止一个。若存在常数 <span class="mathjax-exps">$M$</span> 使得对任意向量 <span class="mathjax-exps">$x\in \mathbb{C}^n$</span>, 有 <span class="mathjax-exps">$\|Ax\|_v \leq M\|x\|_v$</span>, 则 <span class="mathjax-exps">$\|A\|_v = \max_{\|x\|_v=1} \|Ax\|_v \leq M$</span>，即从属于范数 <span class="mathjax-exps">$\|x\|_v$</span> 的算子范数 <span class="mathjax-exps">$\|A\|_v$</span> 是使不等式 <span class="mathjax-exps">$\|Ax\|_v \leq M\|x\|_v$</span> 成立的最小常数，即其放缩效果最好。</p>
<p><span class="callout">4.5.1 Definition: 谱半径</span></p>
<blockquote>
<p>给定复方阵<span class="mathjax-exps">$A$</span>，记</p>
<p></p><div class="mathjax-exps">$$S_p(A) = \{\lambda \mid \lambda \text{ 是 } A \text{ 的特征值}\}$$</div><p></p>
<p>则称<span class="mathjax-exps">$S_p(A)$</span>是矩阵<span class="mathjax-exps">$A$</span>的谱，称<span class="mathjax-exps">$A$</span>的特征值模的最大值为<span class="mathjax-exps">$A$</span>的谱半径，记为<span class="mathjax-exps">$\rho(A)$</span>。</p>
</blockquote>
<p><span class="callout">4.5.1 Theorem: 谱半径不大于矩阵范数</span></p>
<blockquote>
<p>复方阵的谱半径不大于它的任一矩阵范数。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>设<span class="mathjax-exps">$\lambda$</span>是复方阵<span class="mathjax-exps">$A$</span>的任一特征值，<span class="mathjax-exps">$x$</span>是属于<span class="mathjax-exps">$\lambda$</span>的特征向量，则<span class="mathjax-exps">$Ax = \lambda x$</span>。对任意矩阵范数<span class="mathjax-exps">$\|\cdot\|$</span>，有</p>
<p></p><div class="mathjax-exps">$$|\lambda|\|x\| = \|\lambda x\| = \|Ax\| \leq \|A\|\|x\|$$</div><p></p>
<p>注意到<span class="mathjax-exps">$x \neq 0$</span>，则有<span class="mathjax-exps">$|\lambda| \leq \|A\|$</span>，即<span class="mathjax-exps">$\rho(A) \leq \|A\|$</span>。证毕。</p>
</details>
<p><span class="callout">4.5.2 Theorem: 谱半径为矩阵范数的下确界</span></p>
<blockquote>
<p>设<span class="mathjax-exps">$A \in \mathbb{C}^{n \times n}$</span>，任取正常数<span class="mathjax-exps">$\epsilon$</span>，则必存在某个矩阵范数<span class="mathjax-exps">$\|\cdot\|$</span>使得</p>
<p></p><div class="mathjax-exps">$$\|A\| \leq \rho(A) + \epsilon.$$</div><p></p>
</blockquote>
<p><span class="callout">4.5.2 Definition: 盖尔圆盘</span></p>
<blockquote>
<p>设<span class="mathjax-exps">$A = (a_{ij}) \in \mathbb{C}^{n \times n}$</span>，令</p>
<p></p><div class="mathjax-exps">$$\delta_i = \sum_{j=1, j \neq i}^n |a_{ij}|, \quad i = 1, \cdots, n$$</div><p></p>
<p>并定义</p>
<p></p><div class="mathjax-exps">$$G_i = \{z \in \mathbb{C} \mid |z - a_{ii}| \leq \delta_i\}, \quad i = 1, \cdots, n$$</div><p></p>
<p>即<span class="mathjax-exps">$G_i$</span>是复平面上以<span class="mathjax-exps">$a_{ii}$</span>为圆心、<span class="mathjax-exps">$\delta_i$</span>为半径的闭圆盘，称为矩阵<span class="mathjax-exps">$A$</span>的一个盖尔圆盘。</p>
</blockquote>
<p><span class="callout">4.5.3 Theorem: 盖尔中心定理</span></p>
<blockquote>
<p>设<span class="mathjax-exps">$A = (a_{ij}) \in \mathbb{C}^{n \times n}$</span>的<span class="mathjax-exps">$n$</span>个盖尔圆盘为<span class="mathjax-exps">$G_1, \ldots, G_n$</span>，则矩阵<span class="mathjax-exps">$A$</span>的任一特征值<span class="mathjax-exps">$\lambda \in \bigcup_{i=1}^n G_i$</span>。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>证明 设 <span class="mathjax-exps">$\lambda$</span> 是矩阵 <span class="mathjax-exps">$A$</span> 的任一特征值, <span class="mathjax-exps">$x=\left(x_1,\cdots, x_n\right)^{\top}$</span> 是属于特征值 <span class="mathjax-exps">$\lambda$</span> 的特征向量, 则有</p>
<p></p><div class="mathjax-exps">$$a_{i1}x_1+\cdots+ a_{in}x_n=\lambda x_i,\quad i=1,\cdots, n$$</div><p></p>
<p>整理式得</p>
<p></p><div class="mathjax-exps">$$\left(\lambda-a_{ii}\right) x_i=\sum_{k=1, k\neq i}^n a_{ik} x_k \tag{4.5.2}$$</div><p></p>
<p>定义</p>
<p></p><div class="mathjax-exps">$$\left|x_o\right|=\max_{1\leqslant i\leqslant n}\left|x_i\right|&gt;0,\quad\sigma\in\{1,\cdots, n\}$$</div><p></p>
<p>并考察式第 <span class="mathjax-exps">$\sigma$</span> 个方程,得</p>
<p></p><div class="mathjax-exps">$$\left|\lambda-a_{\sigma\sigma}\right|\left|x_\sigma\right|=\left|\sum_{k=1, k\neq\sigma}^n a_{\sigma k} x_k\right|$$</div><p></p>
<p>注意到 <span class="mathjax-exps">$\left|x_0\right|&gt;0$</span> ,则上式可改写为</p>
<p></p><div class="mathjax-exps">$$\begin{align*} \left|\lambda-a_{\sigma\sigma}\right|&amp;=\left|\sum_{k=1, k\neq\sigma}^n a_{\sigma k}\frac{x_k}{\left|x_{\sigma}\right|}\right| \\ &amp;\leqslant\sum_{k=1, k\neq\sigma}^n\left(\left|a_{\sigma k}\right|\frac{\left|x_k\right|}{\left|x_{\sigma}\right|}\right)\leqslant\sum_{k=1, k\neq\sigma}^n\left|a_{\sigma k}\right| \end{align*}$$</div><p></p>
<p>上式表明，特征值 <span class="mathjax-exps">$\lambda$</span> 必在矩阵 <span class="mathjax-exps">$A$</span> 的盖尔圆盘 <span class="mathjax-exps">$G_{\sigma}$</span> 内。因此，矩阵 <span class="mathjax-exps">$A$</span> 的任一特征值必在 <span class="mathjax-exps">$\bigcup\_{i=1}^n G_i$</span> 内。证毕。</p>
</details>
{注}：设 $A^{\top}$ 的盖尔圆盘为 $G'_1, \cdots, G'_n$，则 $G_i$ 与 $G'_i$ 有相同的圆心。因此，矩阵 $A$ 的特征值必满足
$$
\lambda \in \left(\bigcup_{i=1}^n G_i\right) \cap \left(\bigcup_{i=1}^n G'_i\right)
$$
<p><span class="callout">4.5.4 Theorem: 盖尔圆盘定理续</span></p>
<blockquote>
<p>设<span class="mathjax-exps">$A=\left(a_{ij}\right)\in \mathbb{C}^{n\times n}$</span>的盖尔圆盘为<span class="mathjax-exps">$G_1,\cdots, G_n$</span>，若其中的<span class="mathjax-exps">$k$</span>个盖尔圆盘的并集形成一个连通区域，且该区域与其余<span class="mathjax-exps">$n-k$</span>个圆盘都不相交，则此连通区域内恰有<span class="mathjax-exps">$k$</span>个特征值。特别地，孤立盖尔圆盘内有且仅有一个特征值。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
<p>设<span class="mathjax-exps">$D=\text{diag}(a_{11},\cdots,a_{nn})\in \mathbb{C}^{n\times n}$</span>和<span class="mathjax-exps">$B=A-D$</span>，并令<span class="mathjax-exps">$A(\varepsilon)=D+\varepsilon B$</span>，其中<span class="mathjax-exps">$\varepsilon \in [0,1]$</span>。显然，<span class="mathjax-exps">$A(0)=D$</span>，<span class="mathjax-exps">$A(1)=A$</span>，且<span class="mathjax-exps">$A(\varepsilon)$</span>与<span class="mathjax-exps">$A$</span>矩阵的盖尔圆有相同的圆心，但前者的半径是后者的<span class="mathjax-exps">$\varepsilon$</span>倍。由于<span class="mathjax-exps">$\varepsilon \in [0,1]$</span>，故<span class="mathjax-exps">$A(\varepsilon)$</span>的任一盖尔圆都在<span class="mathjax-exps">$A$</span>的相应盖尔圆内。<br>
当<span class="mathjax-exps">$\varepsilon$</span>从 0 连续地变为 1 时，矩阵<span class="mathjax-exps">$A(\varepsilon)$</span>的<span class="mathjax-exps">$n$</span>个特征值将连续变化，即特征值函数（以<span class="mathjax-exps">$\varepsilon$</span>为自变量）在复平面上是<span class="mathjax-exps">$n$</span>条连续的曲线，每条曲线的起点分别为<span class="mathjax-exps">$A$</span>（或<span class="mathjax-exps">$D$</span>）的对角元素，即某一盖尔圆的圆心，曲线终点为<span class="mathjax-exps">$A$</span>的某一特征值。由定理 4.5.3 知，这<span class="mathjax-exps">$n$</span>条连续曲线不能超出所有的盖尔圆。因此，<span class="mathjax-exps">$A$</span>的<span class="mathjax-exps">$k$</span>个盖尔圆盘所围的连通区域中有且仅有<span class="mathjax-exps">$k$</span>条曲线，即有且仅有<span class="mathjax-exps">$A$</span>的<span class="mathjax-exps">$k$</span>个特征值。当<span class="mathjax-exps">$k=1$</span>时，此连通域内有且仅有一个特征值。<br>
证毕。</p>
</details>
<p>令 <span class="mathjax-exps">$A=\begin{bmatrix} 0 &amp; -0.4 \\ 0.9 &amp; 1 \end{bmatrix}$</span>，下图展示了矩阵 <span class="mathjax-exps">$A(\varepsilon)$</span> 的特征值随矩阵变化的情况：</p>
<p><img src="./assert/%E7%9B%96%E5%B0%94%E5%9C%86%E7%9B%98.jpg" alt="特征值随矩阵变化"></p>
<p><span class="callout">4.5.1 Corollary: 非奇异矩阵的盖尔圆盘</span></p>
<blockquote>
<p>设矩阵 <span class="mathjax-exps">$A\in \mathbb{C}^{n\times n}$</span> 的 <span class="mathjax-exps">$n$</span> 个盖尔圆盘为 <span class="mathjax-exps">$G_1,\cdots, G_n$</span>，若原点 <span class="mathjax-exps">$0\notin \bigcup_{i=1}^n G_i$</span>，则矩阵 <span class="mathjax-exps">$A$</span> 必为非奇异矩阵。</p>
</blockquote>
<p><span class="callout">4.5.2 Corollary: 行(列)对角线占优矩阵</span></p>
<blockquote>
<p>设 <span class="mathjax-exps">$A=\left(a_{ij}\right)\in \mathbb{C}^{n\times n}$</span> 是对角占优矩阵，即对 <span class="mathjax-exps">$i=1,\cdots, n$</span>，有</p>
</blockquote>
<p></p><div class="mathjax-exps">$$\left|a_{ii}\right|&gt;\sum_{j=1, j\neq i}^n \left|a_{ij}\right| \quad \text{(列对角占优)}$$</div><p></p>
<blockquote>
<p>或</p>
<p></p><div class="mathjax-exps">$$\left|a_{ii}\right|&gt;\sum_{j=1, j\neq i}^n \left|a_{ij}&gt;\right| \quad \text{(行对角占优)}$$</div><p></p>
<p>则矩阵 <span class="mathjax-exps">$A$</span> 非奇异。</p>
</blockquote>
<p>{注}：在使用盖尔圆估计矩阵 <span class="mathjax-exps">$A$</span> 的特征值时，总希望获得更多的孤立圆，这时可采取如下方法：<br>
取合适的非零实数 <span class="mathjax-exps">$d_1, \cdots, d_n$</span>，并令 <span class="mathjax-exps">$D=\text{diag}(d_1, \cdots, d_n)$</span>，则</p>
<p></p><div class="mathjax-exps">$$B = DAD^{-1} = \left(a_{ij} \frac{d_i}{d_j}\right)_{n\times n}$$</div><p></p>
<p>显然，矩阵 <span class="mathjax-exps">$A$</span> 与 <span class="mathjax-exps">$B$</span> 相似，它们具有完全相同的特征值。我们可依据矩阵 <span class="mathjax-exps">$B$</span> 的盖尔圆来估计矩阵 <span class="mathjax-exps">$A$</span> 的特征值。通常 <span class="mathjax-exps">$d_i$</span> 的选取办法如下：<br>
(1) 若取 <span class="mathjax-exps">$d_i&lt;1$</span>，其余元素为 1，则第 <span class="mathjax-exps">$i$</span> 个盖尔圆盘 <span class="mathjax-exps">$G_i$</span> 会缩小，其余所有盖尔圆盘会放大；<br>
(2) 若取 <span class="mathjax-exps">$d_i&gt;1$</span>，其余元素为 1，则第 <span class="mathjax-exps">$i$</span> 个盖尔圆盘 <span class="mathjax-exps">$G_i$</span> 会放大，而其余所有盖尔圆盘会缩小。</p>
<p><span class="callout">4.6.1 Definition: 向量序列按范数收敛</span></p>
<blockquote>
<p>设 <span class="mathjax-exps">$(V,\|\cdot\|_a)$</span> 是 <span class="mathjax-exps">$n$</span> 维赋范线性空间，<span class="mathjax-exps">$x_1, x_2, \cdots, x_k, \cdots$</span> 是 <span class="mathjax-exps">$V$</span> 中的一个向量序列，记为 <span class="mathjax-exps">$\{x_k\}$</span>。若存在 <span class="mathjax-exps">$V$</span> 中向量 <span class="mathjax-exps">$x$</span> 满足</p>
<p></p><div class="mathjax-exps">$$\lim_{k\rightarrow\infty}\|x_k-x\|_a=0$$</div><p></p>
<p>则称向量序列 <span class="mathjax-exps">$\{x_k\}$</span> 按范数 <span class="mathjax-exps">$\|\cdot\|_{\alpha}$</span> 收敛于 <span class="mathjax-exps">$x$</span>，记作</p>
<p></p><div class="mathjax-exps">$$\lim_{k\rightarrow\infty} x_k=x \quad \text{或} \quad x_k\xrightarrow{a} x$$</div><p></p>
<p>不收敛的向量序列称为发散的。</p>
</blockquote>
<p><span class="callout">4.6.1 Theorem: 范数等价定理</span></p>
<blockquote>
<p>设<span class="mathjax-exps">$(V, \|\cdot\|)$</span>是<span class="mathjax-exps">$n$</span>维赋范线性空间，<span class="mathjax-exps">$\{x_k\}$</span>是<span class="mathjax-exps">$V$</span>的一个向量序列。若序列<span class="mathjax-exps">$\{x_k\}$</span>按某种范数收敛于<span class="mathjax-exps">$x$</span>，则序列<span class="mathjax-exps">$\{x_k\}$</span>按任意范数收敛于<span class="mathjax-exps">$x$</span>，即有限维空间中按范数收敛是等价的。</p>
</blockquote>
<details open="">
    <summary>Proof:</summary>
</details>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>